<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux 内存分析——进程和物理结构角度]]></title>
    <url>%2F2019%2F04%2F13%2F1-memory-process-physical%2F</url>
    <content type="text"><![CDATA[前言关于 Linux 内存管理方面一些文章和书籍中都使用大量的篇幅去讲解，本篇文章主要从进程如何使用内存和物理内存如何管理的两个角度出发，去看 linux 系统是如何管理内存的。由于涉及的点比较多，并且本人技术水平有限，一些内容不会讲的太过深入，一些我比较感兴趣的点，我们会在后续文章中进一步学习。 进程如何使用内存进程地址空间所有进程的执行都需要占用一定的内存，那么进程是怎么使用机器上的内存的呢，linux 系统上每一个进程都有自己可以访问的内存地址空间，对应 4G(32位系统) 大小。第一部分为“用户空间”，用来映射其整个进程空间（0x0000 0000－0xBFFF FFFF）即3G字节的虚拟地址；第二部分为“内核空间”，用来映射（0xC000 0000－0xFFFF FFFF）1G字节的虚拟地址。可以看出Linux系统中每个进程的页面目录的第二部分是相同的，所以从进程的角度来看，每个进程有4G字节的虚拟空间， 较低的3G字节是自己的用户空间，最高的1G字节则为与所有进程以及内核共享的系统空间。4G 是进程认为的虚拟地址空间，一个进程实际占用的物理空间通过实际分配的计算。虚拟内存通过页表映射到物理内存，两个进程也可以通过映射到统一物理地址实现内存共享。 上图左边展示的是内核内存地址空间(1G)，右边展示的是用户内存地址空间，每当进程切换用户空间就会跟着变化；而内核空间是由内核负责映射，它并不会跟着进程改变，是固定的，进程访问内核空间的方式：系统调用和中断。内核空间地址有自己对应的页表（init_mm.pgd），用户进程各自有不同的页表。 上图右边讲解了进程地址空间中使用的数据段种类： 代码段(text)：代码段是用来存放可执行文件的操作指令，也就是说是它是可执行程序在内存中的镜像。代码段需要防止在运行时被非法修改，所以只准许读取操作，而不允许写入（修改）操作——它是不可写的。 数据段(data)：数据段用来存放可执行文件中已初始化全局变量，换句话说就是存放程序静态分配的变量和全局变量。 BSS 段：BSS段包含了程序中未初始化的全局变量，在内存中 bss段全部置零。 堆(heap)：堆是用于存放进程运行中被动态分配的内存段，它的大小并不固定，可动态扩张或缩减。当进程调用malloc等函数分配内存时，新分配的内存就被动态添加到堆上（堆被扩张）；当利用free等函数释放内存时，被释放的内存从堆中被剔除（堆被缩减） 栈(stack)：栈是用户存放程序临时创建的局部变量，也就是说我们函数括弧“{}”中定义的变量（但不包括static声明的变量，static意味着在数据段中存放变量）。除此以外，在函数被调用时，其参数也会被压入发起调用的进程栈中，并且待到调用结束后，函数的返回值也会被存放回栈中。由于栈的先进先出特点，所以栈特别方便用来保存/恢复调用现场。从这个意义上讲，我们可以把堆栈看成一个寄存、交换临时数据的内存区。 虚拟内存在内核中的实现进程在内核中以 task_struct 结构体表示，task_struct 中的 mm_struct 结构体用来存放进程地址空间的所有信息。虚拟内存的最小单位是 vma 结构体，其中每一块内存都通过 vm_area_struct 来存放。vma 中记录开始和结束位置，vma 成链表结构存放在 mm_struct 中，另外还有红黑树提供快速定位查找。如下图所示： 系统上查看进程内存上面介绍了进程使用内存的一些理论，那么能否在系统上直观的看到进程使用了哪些内存呢？ 通过/proc/PID/maps 或者 pmap 命令可以看到进程使用 VMA 映射了的内存区域和访问权限。通过/proc/PID/smaps 可以看到更详细的信息。 12345678910111213141516171819202122# pmap -x 53715371: nginx: worker process Address Kbytes RSS Dirty Mode Mapping0000000000400000 564 344 0 r-x-- nginx //代码段000000000068c000 68 68 60 rw--- nginx //数据段000000000069d000 56 12 12 rw--- [ anon ]000000000a0c8000 1812 1684 1684 rw--- [ anon ]0000003ac0a00000 112 40 0 r-x-- ld-2.5.so //代码段0000003ac0c1c000 4 4 4 r---- ld-2.5.so //数据段0000003ac0c1d000 4 4 4 rw--- ld-2.5.so //bss 段0000003ac0e00000 1340 284 0 r-x-- libc-2.5.so0000003ac0f4f000 2044 0 0 ----- libc-2.5.so0000003ac114e000 16 16 8 r---- libc-2.5.so0000003ac1152000 4 4 4 rw--- libc-2.5.so0000003ac1153000 20 20 20 rw--- [ anon ]00002b5751c3d000 4 4 4 rw-s- zero (deleted)00002b5751c3e000 20012 20000 20000 rw--- [ anon ]00007fffbf2ce000 84 20 20 rw--- [ stack ] //进程的栈00007fffbf35e000 12 0 0 r-x-- [ anon ]ffffffffff600000 8192 0 0 ----- [ anon ]---------------- ------ ------ ------total kB 72880 22940 22000 第5列代表执行权限，r，w，x不必说，p=私有 s=共享。在Mapping 列可以看到所映射的文件名。对有名映射而言，是映射的文件名，对匿名映射来说，是此段内存在进程中的作用。[stack]表示本段内存作为栈来使用，[heap]作为堆来使用，其他情况则为无。 其中代码段是 rx 权限，数据段和 bss 有 rw 权限，堆栈可能有 rwx 的权限。上述 C 库所占有的内存是共享的不可写的，实际属于这个进程的私有物理进程很少，这样可以减少大量内存。 进程各文件以及进程内存地址空间结构如下图： 进程用来申请内存的函数创建进程等进程相关操作都需要分配内存给进程。这时进程申请和获得的不是物理地址，仅仅是虚拟地址。实际的物理内存只有当进程真的去访问新获取的虚拟地址时，才会由“请页机制”产生“缺页”异常，从而进入分配实际页框的程序。该异常是虚拟内存机制赖以存在的基本保证，它会告诉内核去为进程分配物理页，并建立对应的页表，这之后虚拟地址才实实在在的映射到了物理地址上。 进程分配内存有两种方式，分别由两个系统调用完成：brk和mmap（不考虑共享内存）。 1、brk是将数据段(.data)的最高地址指针_edata往高地址推； 2、mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。 这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。 在标准C库中，提供了malloc/free函数分配释放内存，这两个函数底层是由brk，mmap，munmap这些系统调用实现的。 创建进程fork()、程序载入execve()、映射文件mmap()、动态内存分配malloc()/brk()等进程相关操作都需要分配内存给进程。不过这时进程申请和获得的还不是实际内存，而是虚拟内存，准确的说是“内存区域”。进程对内存区域的分配最终都会归结到do_mmap（）函数上来（brk调用被单独以系统调用实现，不用do_mmap()）， 内核使用do_mmap()函数创建一个新的线性地址区间。但是说该函数创建了一个新VMA并不非常准确，因为如果创建的地址区间和一个已经存在的地址区间相邻，并且它们具有相同的访问权限的话，那么两个区间将合并为一个。如果不能合并，那么就确实需要创建一个新的VMA了。但无论哪种情况， do_mmap()函数都会将一个地址区间加入到进程的地址空间中－－无论是扩展已存在的内存区域还是创建一个新的区域。 同样，释放一个内存区域应使用函数do_ummap()，它会销毁对应的内存区域。 malloc利用堆动态分配，实际上是调用brk()系统调用，该调用的作用是扩大或缩小进程堆空间（它会修改进程的brk域）。如果现有的内存区域不够容纳堆空间，则会以页面大小的倍数为单位，扩张或收缩对应的内存区域，但brk值并非以页面大小为倍数修改，而是按实际请求修改。因此Malloc在用户空间分配内存可以以字节为单位分配 共享内存实现进程间通讯进程间通讯(IPC)的实现方式有很多种，如管道、消息队列、共享内存、信号量、套接口等等。共享内存是运行在同一台机器上的进程间通信最快的方式，因为数据不需要在不同的进程间复制。通常由一个进程创建一块共享内存区，其余进程对这块内存区进行读写。得到共享内存有两种方式：映射/dev/mem 设备和内存映像文件。前一种方式不给系统带来额外的开销，但在现实中并不常用，因为它控制存取的将是实际的物理内存，在Linux系统下，这只有通过限制Linux系统存取的内存才可以做到，这当然不太实际。常用的方式是通过shmXXX 函数族来实现利用共享内存进行存储的。 64位系统地址空间64 位系统结果怎样呢？ 64 位系统是否拥有 2^64 的地址空间吗？事实上， 64 位系统的虚拟地址空间划分发生了改变： 地址空间大小不是2^32，也不是 2^64 ,而一般是 2^48 。因为并不需要 2^64 这么大的寻址空间，过大空间只会导致资源的浪费。64位Linux一般使用48位来表示虚拟地址空间，40位表示物理地址，这可通过 /proc/cpuinfo 来查看address sizes : 40 bits physical, 48 bits virtual 其中，0x0000000000000000~0x00007fffffffffff 表示用户空间， 0xFFFF800000000000~ 0xFFFFFFFFFFFFFFFF 表示内核空间，共提供 256TB(2^48) 的寻址空间。这两个区间的特点是，第 47 位与 48~63 位相同，若这些位为 0 表示用户空间，否则表示内核空间。 用户空间由低地址到高地址仍然是只读段、数据段、堆、文件映射区域和栈； 从物理内存角度看内存内存页及虚拟内存到物理内存的映射Linux内核管理物理内存是通过分页机制实现的，它将整个内存划分成无数个4k（在i386体系结构中）大小的页，从而分配和回收内存的基本单位便是内存页了。利用分页管理有助于灵活分配内存地址，因为分配时不必要求必须有大块的连续内存，系统可以东一页、西一页的凑出所需要的内存供进程使用。虽然如此，但是实际上系统使用内存时还是倾向于分配连续的内存块，因为分配连续内存时，页表不需要更改，因此能降低TLB的刷新率（频繁刷新会在很大程度上降低访问速度）。 物理页在系统中由页结构struct page描述，系统中所有的页面都存储在数组mem_map[]中，可以通过该数组找到系统中的每一页（空闲或非空闲）。而其中的空闲页面则可由上述提到的以伙伴关系组织的空闲页链表（free_area[MAX_ORDER]）来索引。 虚拟内存通过页表的映射来找到真实的物理内存，即从进程能理解的线性地址(linear address)映射到存储器上的物理地址(phisical address)。页表是固定存在在cache中的，地址映射必须要有硬件支持，mmu（内存管理单元）就是这个硬件。并且需要有cache来保存页表，这个cache就是TLB（Translation lookaside buffer）。另外也存在物理页到页表项的反向映射，反向映射是在回收内存页时用的。 页表映射其实就是通过多级数组实现的，内核从2.6.11开始采用了四级页表，之前是三级页表和二级页表。线性地址 （比如00007fffbf2ce000）转换为二进制后，最高10位对应目录项地址，中间10位对应页表项地址，最后12位对应key 的 value 中存放物理页的起始地址。 为什么要使用多级页表，而不是直接将线性地址映射到物理地址呢？多级页表好处如下： 多级页表不需要保证页目录项和页表项物理内存连续。 使用多级页表可以节省页表内存。使用一级页表，需要连续的内存空间来存放所有的页表项。多级页表通过只为进程实际使用的那些虚拟地址内存区请求页表来减少内存使用量。 例：二级页表中，页目录项大小为 4K 存放1024 个4byte（正好32位） 页表项也是 4K 存放 1024 个 4byte 。也就是说 我只用8k 就能映射 1024 个 页（4K）内存 当然使用页表也是有劣势的，需要多次访问内存，增加了花费的时间,TLB 就是为了减少这个时间的。三级页表图示如下： 物理内存的 ZONE之前讲到每个进程都有自己的内存地址空间，0-3G对于每个进程都是不同的，3-4G的内核空间是相同的。那么内核怎么使用这1G的空间访问所有的物理内存呢？由于开启了分页机制，内核想要访问物理地址空间的话，必须先建立映射关系，然后通过虚拟地址来访问。为了能够访问所有的物理地址空间，就要将全部物理地址空间映射到1G的内核线性空间中，这显然不可能。 x86架构中将内核地址空间划分三部分：ZONE_DMA、ZONE_NORMAL和 ZONE_HIGHMEM。ZONE_HIGHMEM即为高端内存，当系统物理内存较大时，超过896M的内存区域，内核就无法直接通过线性映射直接访问了。这部分内存被称作high memory。其中,64位系统下不会有high memory，因为64位虚拟地址空间非常大（分给kernel的也很大），完全能够直接映射全部物理内存。 在 32 位系统中（内存大于896M时）： ZONE_DMA 的范围是0~16M，该区域的物理页面专门供I/O设备的DMA使用。之所以需要单独管理DMA的物理页面，是因为DMA使用物理地址访问内存，不经过MMU，并且需要连续的缓冲区，所以为了能够提供物理上连续的缓冲区，必须从物理地址空间专门划分一段区域用于DMA。 ZONE_NORMAL 的范围是16M~896M，该区域的物理页面是内核能够直接使用的。ZONE_NORMAL和内核线性空间存在直接映射关系，映射关系写死的，不需要像用户进程地址一样通过页表动态映射。所以内核会将频繁使用的数据如kernel代码、GDT、IDT、PGD、mem_map数组等放在ZONE_NORMAL里。为什么是896，可能是一个经验值吧… ZONE_HIGHMEM 的范围是896M~结束，该区域内核不能直接使用。内核使用剩下的128M线性地址空间不足以完全映射所有的ZONE_HIGHMEM，Linux采取了动态映射的方法，即按需的将ZONE_HIGHMEM里的物理页面映射到kernel space的最后128M线性地址空间里，使用完之后释放映射关系，以供其它物理页面映射。虽然这样存在效率的问题，但是内核毕竟可以正常的访问所有的物理地址空间了。比如，当内核要访问I/O设备存储空间时，就使用ioremap()将位于物理地址高端的mmio区内存映射到内核空间的vmalloc-area中，在使用完之后便断开映射关系。 现在让我们忘记进程地址空间的图，看一下内核地址空间是怎么映射的： 物理内存的 Zone 的划分 、page 数量 在开机的时候就已经决定了，通过dmesg 日志可以看到每一个Zone 的物理地址划分，显然在numa 架构中，只有第一个node 有DMA Zone。 伙伴系统buddy 和 slablinux 是通过页管理物理内存的，内核分配物理页面时为了尽量减少不连续情况，采用了“伙伴”关系来管理空闲页面。Linux中空闲页面的组织和管理利用了伙伴关系，因此空闲页面分配时也需要遵循伙伴关系，最小单位只能是2的幂倍页面大小。内核中分配空闲页面的基本函数是get_free_page/get_free_pages，它们或是分配单页或是分配指定的页面（2、4、8…512页）。内存分配 API 如kmalloc/vmalloc/kmap以及maolloc都是基于Buddy算法之上进行二级内存管理，这些API不直接面对物理内存(内存条)。 通过 /proc/buddyinfo 可以看到机器上各个order 中内存块剩余的数量。 伙伴系统适合分配大的连续内存，对于小的内存申请，例如几个字节几十个字节，分配一整个页框太过于浪费，并且如果需要频繁的获取/释放并不大的连续物理内存怎么办，如几十字节几百字节的获取/释放，这样的话用buddy就不太合适了，所以内核引入了一种新的数据结构：slab。slab 是基于buddy 的，前者是对后者的细化。 slab 的分配机制： slab分配器是基于对象进行管理的，所谓的对象就是内核中的数据结构（例如：task_struct,file_struct 等）。相同类型的对象归为一类，每当要申请这样一个对象时，slab分配器就从一个slab列表（slabs_partial、slabs_full、slabs_empty）中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免内部碎片。slab分配器并不丢弃已经分配的对象，而是释放并把它们保存在内存中。slab分配对象时，会使用最近释放的对象的内存块，因此其驻留在cpu高速缓存中的概率会大大提高。 在/proc/slabinfo文件中有对内核slab情况的记录，如下图： 从上图可以看到内核常规结构的小块内存的slab分配情况，如UDPv6/TCPv6等，其中&lt;active_objs&gt; &lt;num_objs&gt; 分别表示：使用的object个数、object个数、object大小、每个slab可以分的object个个数、每个slab占用的页。 物理内存的申请函数物理内存的分配函数： get_free_pages()或alloc_pages()从normal区域的buddy系统中 使用页框分配器中获得页框。 kmem_cache_alloc()或kmalloc使用slab 分配器为专用或通用对象分配块，从内核内存分配的角度来讲，kmalloc可被看成是get_free_page（s）的一个有效补充，内存分配粒度更灵活了。不过可申请内存的大小有限。 vmalloc() 或 vmalloc_32()从 VMALLOC区域 vmalloc_start（892M+8M）~vmalloc_end之间获得一块非连续内存。vmalloc 优先分配的是high_memory。 即时使用了slab 和 buddy ，但还是无法彻底解决内存外部分片的情况，vmalloc 就是为了利用这些不连续的内存块。vmalloc 申请内存类似进程申请的虚拟内存，需要将内存虚拟地址进行映射。 vmalloc 申请的虚拟内存区域用 vm_struct 结构体表示 ，不是vma 不要弄混。 几种物理内存分配函数的比较： 函数 分配原理 最大内存 其他 __get_free_pages 直接对页框进行操作 4MB 适用于分配较大量的连续物理内存 kmem_cache_alloc 基于slab机制实现 128KB 适合需要频繁申请释放相同大小内存块时使用 kmalloc 基于kmem_cache_alloc实现 128KB 最常见的分配方式，需要小于页框大小的内存时可以使用 vmalloc 建立非连续物理内存到虚拟地址的映射 物理不连续，适合需要大内存，但是对地址连续性没有要求的场合 dma_alloc_coherent 基于__alloc_pages实现 4MB 适用于DMA操作 ioremap 实现已知物理地址到虚拟地址的映射 适用于物理地址已知的场合，如设备驱动 alloc_bootmem 在启动kernel时，预留一段内存，内核看不见 小于物理内存大小，内存管理要求较高 两种角度如何联系起来前面我们介绍了进程是如何使用虚拟内存的，也介绍了物理内存在linux 内核下是如何管理的。那么如何将两个角度联系起来呢，简单来说两者就是通过虚拟内存到物理内存的映射联系起来的。当虚拟内存没有映射到物理内存的时候，发生page_fault 申请物理内存。 下面我们将两个角度联系起来画一张图展示： 进程调用 libc 库中的函数申请内存； libc 库函数调用内核系统调用申请进程虚拟内存地址空间 虚拟内存通过MMU 映射找到物理内存 映射没有建立时，内核调用函数分配物理内存。（各种函数通过gfp_mask flag 来决定在哪个ZONE 优先申请。） 从用户态到内核态我们知道linux 有用户态和内核态的概念，像分配物理内存，从父进程拷贝相关信息，拷贝设置页目录、页表等，这些操作显然不能随便让任何程序都可以做，于是就产生了特权级别的概念，与系统相关的一些特别关键性的操作必须由高级别的程序来完成，这样可以做到集中管理，减少有限资源的访问和使用冲突。 上面我们讲到，进程使用libc库函数申请内存时，会调用内核的系统调用，从用户态到内核态的转换就是通过系统调用实现的（主要是系统调用，还有中端和异常，其实系统调用也是通过软中断实现的）。 Linux的系统调用通过int0x80实现，用系统调用号来区分入口函数，因为用户栈和内核栈不在同一空间，所以使用寄存器传递参数。 操作系统实现系统调用的基本过程是： 应用程序调用库函数（API）； API将系统调用号存入EAX，然后通过中断调用使系统进入内核态； 内核中的中断处理函数根据系统调用号，调用对应的内核函数（系统调用）； 系统调用完成相应功能，将返回值存入EAX，返回到中断处理函数； 中断处理函数返回到API中； API将EAX返回给应用程序。 书籍推荐及相关链接链接： slab分配: https://blog.csdn.net/yunsongice/article/details/5272715 内存回收：https://www.cnblogs.com/tolimit/p/5435068.html 书籍： 入门：《Linux内核设计与实现》 进阶：《深入理解Linux内核]]></content>
  </entry>
  <entry>
    <title><![CDATA[进程地址空间]]></title>
    <url>%2F2018%2F09%2F20%2F13-%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%2F</url>
    <content type="text"><![CDATA[前言内核除了需要管理自己使用的物理内存，还要管理用户空间中进程使用的内存。这部分内存称为进程地址空间。由于使用虚拟内存，所以每个进程都认为自己拥有整个物理内存。 进程的地址空间进程的内存地址空间由可寻址的虚拟内存组成，根据架构不同有32位或64位的独立连续的地址空间（flat）。两个内存可能有相同的内存地址，但其实互不相干，这种称为线程。 尽管进程可以访问2^32GB 或者 2^64 GB 的虚拟内存，但是不代表进程有权限访问所有虚拟地址，一个进程可以访问的合法地址空间称为memory areas 内存区域.进程可以动态的增加或减少自己的内存区域。 如果进程访问了有效内存区域外的内存地址，内核会终止进程并报“Segmentation Fault”。 进程的内存区域包含一下内存对象： A memory map of the executable file’s code, called the text section. A memory map of the executable file’s initialized global variables, called the data section. A memory map of the zero page (a page consisting of all zeros, used for purposes such as this) containing uninitialized global variables, called the bss section.1 A memory map of the zero page used for the process’s user-space stack. (Do not confuse this with the process’s kernel stack, which is separate and maintained and used by the kernel.) An additional text, data, and bss section for each shared library, such as the C library and dynamic linker, loaded into the process’s address space. Any memory mapped files. Any shared memory segments. Any anonymous memory mappings, such as those associated with malloc(). 内存描述符 mm_structmm_struct 结构体用来存放进程地址空间的所有信息。通常每个进程都有唯一的 mm_struct.所有的 mm_struct 结构体通过 mmlist 双向链表链接，链表的首元素是 init_mm 内存描述符，代表init 进程的地址空间，操作该链表需要使用 mmlist_lock 锁防止并发访问。 mm_struct 源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154struct mm_struct &#123; //指向线性区对象的链表头 struct vm_area_struct * mmap; /* list of VMAs */ //指向线性区对象的红黑树 struct rb_root mm_rb; //指向最近找到的虚拟区间 struct vm_area_struct * mmap_cache; /* last find_vma result */ //用来在进程地址空间中搜索有效的进程地址空间的函数 unsigned long (*get_unmapped_area) (struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags); unsigned long (*get_unmapped_exec_area) (struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags); //释放线性区时调用的方法， void (*unmap_area) (struct mm_struct *mm, unsigned long addr); //标识第一个分配文件内存映射的线性地址 unsigned long mmap_base; /* base of mmap area */ unsigned long task_size; /* size of task vm space */ /* * RHEL6 special for bug 790921: this same variable can mean * two different things. If sysctl_unmap_area_factor is zero, * this means the largest hole below free_area_cache. If the * sysctl is set to a positive value, this variable is used * to count how much memory has been munmapped from this process * since the last time free_area_cache was reset back to mmap_base. * This is ugly, but necessary to preserve kABI. */ unsigned long cached_hole_size; //内核进程搜索进程地址空间中线性地址的空间空间 unsigned long free_area_cache; /* first hole of size cached_hole_size or larger */ //指向页表的目录 pgd_t * pgd; //共享进程时的个数 atomic_t mm_users; /* How many users with user space? */ //内存描述符的主使用计数器，采用引用计数的原理，当为0时代表无用户再次使用 atomic_t mm_count; /* How many references to "struct mm_struct" (users count as 1) */ //线性区的个数 int map_count; /* number of VMAs */ struct rw_semaphore mmap_sem; //保护任务页表和引用计数的锁 spinlock_t page_table_lock; /* Protects page tables and some counters */ //mm_struct结构，第一个成员就是初始化的mm_struct结构， struct list_head mmlist; /* List of maybe swapped mm's. These are globally strung * together off init_mm.mmlist, and are protected * by mmlist_lock */ /* Special counters, in some configurations protected by the * page_table_lock, in other configurations by being atomic. */ mm_counter_t _file_rss; mm_counter_t _anon_rss; mm_counter_t _swap_usage; //进程拥有的最大页表数目 unsigned long hiwater_rss; /* High-watermark of RSS usage */、 //进程线性区的最大页表数目 unsigned long hiwater_vm; /* High-water virtual memory usage */ //进程地址空间的大小，锁住无法换页的个数，共享文件内存映射的页数，可执行内存映射中的页数 unsigned long total_vm, locked_vm, shared_vm, exec_vm; //用户态堆栈的页数， unsigned long stack_vm, reserved_vm, def_flags, nr_ptes; //维护代码段和数据段 unsigned long start_code, end_code, start_data, end_data; //维护堆和栈 unsigned long start_brk, brk, start_stack; //维护命令行参数，命令行参数的起始地址和最后地址，以及环境变量的起始地址和最后地址 unsigned long arg_start, arg_end, env_start, env_end; unsigned long saved_auxv[AT_VECTOR_SIZE]; /* for /proc/PID/auxv */ struct linux_binfmt *binfmt; cpumask_t cpu_vm_mask; /* Architecture-specific MM context */ mm_context_t context; /* Swap token stuff */ /* * Last value of global fault stamp as seen by this process. * In other words, this value gives an indication of how long * it has been since this task got the token. * Look at mm/thrash.c */ unsigned int faultstamp; unsigned int token_priority; unsigned int last_interval; //线性区的默认访问标志 unsigned long flags; /* Must use atomic bitops to access the bits */ struct core_state *core_state; /* coredumping support */#ifdef CONFIG_AIO spinlock_t ioctx_lock; struct hlist_head ioctx_list;#endif#ifdef CONFIG_MM_OWNER /* * "owner" points to a task that is regarded as the canonical * user/owner of this mm. All of the following must be true in * order for it to be changed: * * current == mm-&gt;owner * current-&gt;mm != mm * new_owner-&gt;mm == mm * new_owner-&gt;alloc_lock is held */ struct task_struct *owner;#endif#ifdef CONFIG_PROC_FS /* store ref to file /proc/&lt;pid&gt;/exe symlink points to */ struct file *exe_file; unsigned long num_exe_file_vmas;#endif#ifdef CONFIG_MMU_NOTIFIER struct mmu_notifier_mm *mmu_notifier_mm;#endif#ifdef CONFIG_TRANSPARENT_HUGEPAGE pgtable_t pmd_huge_pte; /* protected by page_table_lock */#endif /* reserved for Red Hat */#ifdef __GENKSYMS__ unsigned long rh_reserved[2];#else /* How many tasks sharing this mm are OOM_DISABLE */ union &#123; unsigned long rh_reserved_aux; atomic_t oom_disable_count; &#125;; /* base of lib map area (ASCII armour) */ unsigned long shlib_base;#endif&#125;; 内存描述符的分配task_struct 中 mm 域中存放该进程的内存描述符。fork()函数调用 copy_mm()复制父进程的内存描述符。子进程实际是通过kernel/fork.c 文件的 allocate_mm() 函数 从 mm_cachep slab cache 中分配。 如果父进程希望和子进程共享地址空间，在调用 clone()时设置 CLONE_VM 标志，这样的进程就是线程，是否共享地址空间，也是进程和线程唯一的区别。 指定 CLONE_VM 后，不再调用allocate_mm()， 12345678if (clone_flags &amp; CLONE_VM) &#123; /* * current is the parent process and * tsk is the child process during a fork()*/ atomic_inc(&amp;current-&gt;mm-&gt;mm_users); tsk-&gt;mm = current-&gt;mm;&#125; 内存描述符的撤销进程退出 调用 kernel/exit.c 中的 exit_mm()，其中 mmput() -1 mm_user 计数，到0后，mmdrop() -1 mm_count 计数。也为0后代表无人使用。free_mm() 宏通过kmem_cache_free() 将 mm_struct 结构体归还到 mm_cachep slab cache. 内核线程内核线程没有进程地址空间，也没有自己的 mm_struct。内核线程的 mm域 为空。这也是内核线程的真实含义——没有用户上下文。内核线程使用调度前一个进程的内存描述符，内核发现 mm域 为 NULL 时，保留前一个进程地址空间，内核线程不访问用户空间内存，只使用地址空间和内核内存相关的信息，那部分对于所有进程都是一样的。 虚拟内存区域(Virtual Memory Areas)VMA 由结构体vm_area_struct 表示，描述一个指定地址空间的内连续的独立的内存范围。VMA 中 vm_mm 指向对应的 mm_struct,VMA 对于指向的mm_struct 是独一无二的。 每个 VMA 作为一个单独的内存对象管理，有一致的属性。每一个 VMA 可以代表不同类型的内存区域，比如内存映射文件或进程用户空间栈。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354struct vm_area_struct &#123; /* The first cache line has the info for VMA tree walking. */ unsigned long vm_start; /* Our start address within vm_mm. */ unsigned long vm_end; /* The first byte after our end address within vm_mm. */ /* linked list of VM areas per task, sorted by address */ struct vm_area_struct *vm_next, *vm_prev; struct rb_node vm_rb; /* * Largest free memory gap in bytes to the left of this VMA. * Either between this VMA and vma-&gt;vm_prev, or between one of the * VMAs below us in the VMA rbtree and its -&gt;vm_prev. This helps * get_unmapped_area find a free area of the right size. */ unsigned long rb_subtree_gap; /* Second cache line starts here. */ struct mm_struct *vm_mm; /* The address space we belong to. */ pgprot_t vm_page_prot; /* Access permissions of this VMA. */ unsigned long vm_flags; /* Flags, see mm.h. */ /* * For areas with an address space and backing store, * linkage into the address_space-&gt;i_mmap interval tree, or * linkage of vma in the address_space-&gt;i_mmap_nonlinear list. */ union &#123; struct &#123; struct rb_node rb; unsigned long rb_subtree_last; &#125; linear; struct list_head nonlinear; &#125; shared; /* * A file's MAP_PRIVATE vma can be in both i_mmap tree and anon_vma * list, after a COW of one of the file pages. A MAP_SHARED vma * can only be in the i_mmap tree. An anonymous MAP_PRIVATE, stack * or brk vma (with NULL file) can only be in an anon_vma list. */ struct list_head anon_vma_chain; /* Serialized by mmap_sem &amp; * page_table_lock */ struct anon_vma *anon_vma; /* Serialized by page_table_lock */ /* Function pointers to deal with this struct. */ const struct vm_operations_struct *vm_ops; /* Information about our backing store: */ unsigned long vm_pgoff; /* Offset (within vm_file) in PAGE_SIZE units, *not* PAGE_CACHE_SIZE */ struct file * vm_file; /* File we map to (can be NULL). */ void * vm_private_data; /* was vm_pte (shared mem) */ VMA 操作函数上面的结构体中 vm_ops 指向 VMA 结构体一些操作函数，和 VFS 一样，不同类型的 vma 实现特定的实例方法。 12345678struct vm_operations_struct &#123;void (*open) (struct vm_area_struct *); //given memory area is added to an address spacevoid (*close) (struct vm_area_struct *); //given memory area is removed from an address spaceint (*fault) (struct vm_area_struct *, struct vm_fault *); //invoked by the page fault handler when a page that is not present in physical memory is accessedint (*page_mkwrite) (struct vm_area_struct *vma, struct vm_fault *vmf); int (*access) (struct vm_area_struct *, unsigned long ,void *, int, int);//invoked by access_process_vm() when get_user_pages() fails&#125;; VMA 的树形结构和链表结构VMA 通过 mmap 和 mm_rb 来访问内存区域，mmap 通过链表的形式存放 VMA 结构体，主要用于遍历，按照地址增长排序，mmap 执行链表第一个内存区域。mm_rb 通过红黑树来存放 VMA 结构体，mm_rb 指向红黑树根节点，红黑数主要用于定位特定内存区域。两种结构中存放完全相同的 vm_area_struct 结构体,只是数据结构不同。 查看实际进程内存区域使用 /proc/PID/maps 或者 pmap 命令可以查看给定进程使用的内存空间以及使用内存的程序/库等。 12345678910111213141516171819202122# pmap -x 53715371: nginx: worker process Address Kbytes RSS Dirty Mode Mapping0000000000400000 564 344 0 r-x-- nginx //代码段000000000068c000 68 68 60 rw--- nginx //数据段000000000069d000 56 12 12 rw--- [ anon ]000000000a0c8000 1812 1684 1684 rw--- [ anon ]0000003ac0a00000 112 40 0 r-x-- ld-2.5.so //代码段0000003ac0c1c000 4 4 4 r---- ld-2.5.so //数据段0000003ac0c1d000 4 4 4 rw--- ld-2.5.so //bss 段0000003ac0e00000 1340 284 0 r-x-- libc-2.5.so0000003ac0f4f000 2044 0 0 ----- libc-2.5.so0000003ac114e000 16 16 8 r---- libc-2.5.so0000003ac1152000 4 4 4 rw--- libc-2.5.so0000003ac1153000 20 20 20 rw--- [ anon ]00002b5751c3d000 4 4 4 rw-s- zero (deleted)00002b5751c3e000 20012 20000 20000 rw--- [ anon ]00007fffbf2ce000 84 20 20 rw--- [ stack ] //进程的栈00007fffbf35e000 12 0 0 r-x-- [ anon ]ffffffffff600000 8192 0 0 ----- [ anon ]---------------- ------ ------ ------total kB 72880 22940 22000 可以看到代码段是 rx 权限，数据段和 bss 有 rw 权限，堆栈可能有 rwx 的权限。 上述 C 库所占有的内存是共享的不可写的，实际属于这个进程的私有物理进程很少，这样可以减少大量内存。 操作内存的函数find_vma()find_vma()用于找到给定的内存地址属于哪一个内存区域，返回一个vm_area_struct 结构体 12345678910111213141516171819202122232425262728293031323334/* Look up the first VMA which satisfies addr &lt; vm_end, NULL if none. */struct vm_area_struct *find_vma(struct mm_struct *mm, unsigned long addr)&#123; struct vm_area_struct *vma = NULL; /* Check the cache first. */ /* (Cache hit rate is typically around 35%.) */ vma = ACCESS_ONCE(mm-&gt;mmap_cache); if (!(vma &amp;&amp; vma-&gt;vm_end &gt; addr &amp;&amp; vma-&gt;vm_start &lt;= addr)) &#123; struct rb_node *rb_node; //如果缓存未命中开始查找红黑树 rb_node = mm-&gt;mm_rb.rb_node; vma = NULL; while (rb_node) &#123; struct vm_area_struct *vma_tmp; vma_tmp = rb_entry(rb_node, struct vm_area_struct, vm_rb); if (vma_tmp-&gt;vm_end &gt; addr) &#123; vma = vma_tmp; if (vma_tmp-&gt;vm_start &lt;= addr) break; rb_node = rb_node-&gt;rb_left; &#125; else rb_node = rb_node-&gt;rb_right; &#125; if (vma) mm-&gt;mmap_cache = vma; &#125; return vma;&#125; mmap() and do_mmap() 创建地址空间do_mmap() 函数创建一个新的线性地址空间，但并不一定创建新的 VMA ，如果创建的 VMA 和已存在的地址区间相邻且相同权限，会合并为一个。否则创建新的 VMA，从 vm_area_cachep slab cache 中分配一个vm_area_struct，然后通过vma_link()加入到链表和红黑树中，更新total_vm,最后返回新的地址区间的初始地址。 1234567unsigned long do_mmap(struct file *file, unsigned long addr, unsigned long len, unsigned long prot,unsigned long flag, unsigned long offset)//file 映射的文件//offset 具体映射从文件的偏移量开始,长度为 lan//file 和 offset 都为0 是匿名映射//prot 内存访问权限//flag VMA 标志 在用户空间通过mmap()系统调用获取内核函数do_mmap()的功能。 do_munmap()do_munmap() 删除地址空间,从 start 开始删除 len 长。1int do_munmap(struct mm_struct *mm, unsigned long start, size_t len) 页表虽然程序使用的是虚拟内存，但是 cpu 需要操作物理内存，虚拟内存到物理内存的映射使用页表，Linux 使用三级页表，可以节省页表所占用的空间。 顶级页表也是一级页表(PGD)指向二级页表(PMD)指向最后的页表(PTE)指向物理页面。 多数体系结构，查找页表是硬件完成的，每个进程的内存描述符中 pgd 指向一级页表。页表对应的结构体依赖体系结构。 TLB ：虚拟地址到物理地址映射的硬件缓存]]></content>
      <tags>
        <tag>kernel</tag>
        <tag>memory</tag>
        <tag>process</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内核中内存管理]]></title>
    <url>%2F2018%2F09%2F16%2F12-%E5%86%85%E6%A0%B8%E4%B8%AD%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[内存页 MMU ：内存管理单元，将虚拟内存转化为物理地址的硬件。 因为 MMU 通常以页为单位处理内存，所以从虚拟内存的角度来说，内核中页是最小的单位。 一般 32 位系统使用4k页，64 位系统使用8k页。 内核使用 struct page 结构体存放物理页。page 与物理页相关，而非虚拟页，当内存页被swap后，可能不再和同一个page相关联。 可以通过page_address(page) 函数获取物理页page 对应的逻辑地址。page 的内核代码 123456789101112defined in &lt;linux/mm_types.h&gt;struct page &#123; unsigned long flags; //内存页状态，定义在&lt;linux/page-flags.h&gt;. atomic_t _count; //引用计数 atomic_t _mapcount; unsigned long private; struct address_space *mapping; pgoff_t index; struct list_head lru; void *virtual; //在虚拟内存中的地址&#125;; ZONE由于硬件的原因，内核对于内存中不同物理地址的内存并不一视同仁。由于这种限制，内存将内存页划分了区（zone）。ZONE的划分是为了管理页的一种逻辑分组。内存分配不能同时在两个zone 分配。 有些硬件存在下面两种缺陷引起的内存寻址问题，所以需要将内存分区。 一些硬件只能用特定的内存地址来执行DMA（直接内存访问）。 一些体系结构的内存物理寻址范围大于虚拟寻址范围，导致一些内存不能映射到内核空间。 linux 主要有下面 4 种 ZONE ZONE_DMA—This zone contains pages that can undergo DMA. ZONE_DMA32—Like ZOME_DMA, this zone contains pages that can undergo DMA. Unlike ZONE_DMA, these pages are accessible only by 32-bit devices. On some architectures, this zone is a larger subset of memory. ZONE_NORMAL—This zone contains normal, regularly mapped, pages. ZONE_HIGHMEM—This zone contains “high memory,” which are pages not perma￾nently mapped into the kernel’s address space. 例如 X86-32 架构，ISA 设备只能访问物理内存的前16M，高于896M的内存不能直接映射。剩下的就是NORMAL区。如果体系结构没有限制，那么全部都是NORMAL区。 Zone Description Physical Memory ZONE_DMA DMA-able pages &lt; 16MB ZONE_NORMAL Normally addressable pages 16–896MB ZONE_HIGHMEM Dynamically mapped pages &gt; 896MB zone 的水线：每一个zone 都有自己的最小值，最低值，最高值三个水线，使用水线设置合适的内存消耗基准，水线随着空暇内存变化 zone 的内核代码12345678910111213141516171819202122232425262728defined in &lt;linux/mmzone.h&gt;struct zone &#123; unsigned long watermark[NR_WMARK]; //持有该区的最小最低最高的水位值。 unsigned long lowmem_reserve[MAX_NR_ZONES]; struct per_cpu_pageset pageset[NR_CPUS]; spinlock_t lock; //自旋锁 struct free_area free_area[MAX_ORDER] spinlock_t lru_lock; struct zone_lru &#123; struct list_head list; unsigned long nr_saved_scan; &#125;lru[NR_LRU_LISTS]; struct zone_reclaim_stat reclaim_stat; unsigned long pages_scanned; unsigned long flags; atomic_long_t vm_stat[NR_VM_ZONE_STAT_ITEMS]; int prev_priority; unsigned int inactive_ratio; wait_queue_head_t *wait_table; unsigned long wait_table_hash_nr_entries; unsigned long wait_table_bits; struct pglist_data *zone_pgdat; unsigned long zone_start_pfn; unsigned long spanned_pages; unsigned long present_pages; const char *name;&#125;; 获取页内核提供了一些请求内存和释放内存的底层接口， 请求内存函数 描述 alloc_page(gfp_mask) Allocates a single page and returns a pointer to its alloc_pages(gfp_mask, order) Allocates 2order pages and returns a pointer to the first page’s page structure __get_free_page(gfp_mask) Allocates a single page and returns a pointer to its logical address __get_free_pages(gfp_mask, order) Allocates 2order pages and returns a pointer to the first page’s logical address get_zeroed_page(gfp_mask) Allocates a single page, zero its contents and returns a pointer to its logical address 释放内存接口:123void __free_pages(struct page *page, unsigned int order) void free_pages(unsigned long addr, unsigned int order) void free_page(unsigned long addr) kmalloc()和上面获取页的接口不同，kmalloc()主要用于申请字节为单位的内存。kmalloc() 返回一个指向内存块的指针，至少是 size 大小，分配的内存区在物理上是连续的。 1void * kmalloc(size_t size, gfp_t flags) gfp_mask 标志 行为修饰符：分配内存时的动作 区修饰符：从哪个 zone 分配内存 类型：组合上面两个 GFP_ATOMIC 分配内存是不能睡眠，在内存紧缺时容易失败。 GFP_KERNEL 可以睡眠，用于安全调度的进程上下文中，成功率高。 Situation | Solution|—|—|Process context, can sleep | Use GFP_KERNEL.Process context, cannot sleep | Use GFP_ATOMIC, or perform your allocations with GFP_KERNEL at an earlier or later point when you can sleepInterrupt handler | Use GFP_ATOMIC.Softirq | Use GFP_ATOMIC.Tasklet | Use GFP_ATOMIC.Need DMA-able memory, can | Use (GFP_DMA | GFP_KERNEL). sleepNeed DMA-able memory, cannot | Use (GFP_DMA | GFP_ATOMIC), or perform your sleep allocation at an earlier point when you can sleep. kfree()kfree() 释放由kmalloc()申请的内存。 1234567void kfree(const void *ptr)//例子char *buf;buf = kmalloc(BUF_SIZE, GFP_ATOMIC); if (!buf)/* error allocating memory ! */kfree(buf); vmalloc()类似kmalloc，但是物理内存地址可以不连续，虚拟内存地址是连续的。可以睡眠。 一般只有硬件要求得到物理地址连续的内存。软件可以使用只有虚拟地址连续的内存。很多内核代码虽然不需要连续的物理内存，但还是使用kmalloc，因为性能好，不需要做逻辑映射。 123456789//declared in &lt;linux/vmalloc.h&gt;void * vmalloc(unsigned long size)void vfree(const void *addr)//例子char *buf;buf = vmalloc(16 * PAGE_SIZE); /* get 16 pages */ if (!buf)vfree(buf); Slab 层有很多对象存放在链表结构中，在不用的时候空闲链表也已经占用内存。内核不能不能控制这些空闲链表的回收，尤其是在内存紧缺时。所以引入了 slab 分配器。slab 扮演了一个通用的数据结构缓存角色。 slab 把不同类型的对象放到不同的 caches 中。 一个 slab 由一个或者多个物理上的连续页组成，一般情况只有一个页，每一个cache 有多个 slab。 一个 slab 有三个状态：full, partial, or empty. 先从 partial 开始填充。 cache 用 kmem_cache 结构表示 包含三个链表 slabs_full,slabs_partial,slabs_empty,链表中包含所有的 slab。 12345678910struct slab &#123; struct list_head list; /* full, partial, or empty list */ unsigned long colouroff; /* offset for the slab coloring */ void *s_mem; /* first object in the slab */ unsigned int inuse; /* allocated objects in the slab */ kmem_bufctl_t free; /* first free object, if any */&#125;;slab 的创建：通过 *kmem_getpages（）中调用的 _get_free_pages()函数分配内存页。 slab 是在 cache 的基础之上，提供给内核一个简单的接口，通过接口来对 cache 进行分配和撤销。slab 起一个分配器的作用，可以为具体的 object 分配内存。 12345678910//cache 的创建（slab 分配器的接口）：//返回一个指向 cache 的指针。align 是 slab 第一个对象的偏移量，用于内存对齐struct kmem_cache * kmem_cache_create(const char *name, size_t size,size_t align, unsigned long flags, void (*ctor)(void *));//撤销 cacheint kmem_cache_destroy(struct kmem_cache *cachep)//创建 cache 后，获取对象，没有空闲 slab 的话，通过上面的*kmem_getpages（）获取新的页。void * kmem_cache_alloc(struct kmem_cache *cachep, gfp_t flags) task_struct 对象的 slab 和 cache 创建例子1234567891011121314151617181920//1.首先创建一个全局变量存放 task_struct 的 cachestruct kmem_cache *task_struct_cachep;task_struct_cachep = kmem_cache_create(“task_struct”, sizeof(struct task_struct),ARCH_MIN_TASKALIGN, SLAB_PANIC | SLAB_NOTRACK, NULL);//2.进程调用 fork()时，会创建新的process descriptor：struct task_struct *tsk;tsk = kmem_cache_alloc(task_struct_cachep, GFP_KERNEL); if (!tsk) return NULL;//3.process descriptor 被撤销kmem_cache_free(task_struct_cachep, tsk);//4.task_struct_cachep cache 是不会被撤销的，因为内核经常要用，非要撤销的话：int err;err = kmem_cache_destroy(task_struct_cachep); if (err)/* error destroying cache */ 其他Stack 上内存的静态分配32位 和 64位 页的大小为4K 和 8K，一般进程有两页的内核栈，也可以设置单页内核栈。 随着运行时间的增加，物理内存碎片增加，分配连续的页越来越难。当单页栈设置后，中断程序不再和进程放在同一个栈内，有自己的中断栈。 栈的溢出会覆盖紧邻堆栈末端的内容，溢出后 down 机还好，否则会破坏数据。 高端内存的映射高端内存的永久映射数量是有限的，不需要时需要解除。通过函数kmap进行映射，可以睡眠。kmap_atomic提供了原子性的临时映射。不会被阻塞，禁止内核抢断。 per CPU 新接口对于 smp 系统，多个 cpu 可以有自己才能访问的数据，这样不需要锁，只需要注意内核抢占的问题即可。12345678910void *percpu_ptr; unsigned long *foo;percpu_ptr = alloc_percpu(unsigned long); //为 cpu 动态分配内存，类似 kmalloc()if (!ptr)/* error allocating memory .. */foo = get_cpu_var(percpu_ptr); //获取当前 CPU 上的指定数据，会禁止内核抢断/* manipulate foo .. */ put_cpu_var(percpu_ptr); //开启内核抢断 分配内存函数的选择 需求 函数 特点 连续的物理页 kmalloc() 可以通过 flag 决定是否可以睡眠， 高端内存 alloc_pages() 返回一个 page 的指针，而不是逻辑地址，因为可能没有映射 获取真正的指针 kmap() 会把高端内存映射到逻辑地址 不需要内存连续的地址 vmalloc() 需要映射，有性能损失 创建和撤销数据结构 slab 使用 cache 动态分配]]></content>
      <tags>
        <tag>kernel</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[XFS-quotacheck源码]]></title>
    <url>%2F2018%2F09%2F11%2F11-XFS-quotacheck%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[流程图12345graph TDxfs_mountfs--&gt;xfs_qm_mount_quotasxfs_qm_mount_quotas--&gt;XFS_QM_NEED_QUOTACHECKXFS_QM_NEED_QUOTACHECK--&gt;m_sb.sb_qflagsm_sb.sb_qflags--&gt;xfs_qm_quotacheck xfs_mountfsxfs_mount.c 会看 xfs 是否开启了 quota 调用 xfs_qm_mount_quotas（）12345678910111213141516171819202122232425262728293031323334353637383940414243444546xfs_mountfs( struct xfs_mount *mp)&#123; struct xfs_sb *sbp = &amp;(mp-&gt;m_sb); struct xfs_inode *rip; __uint64_t resblks; uint quotamount = 0; uint quotaflags = 0; int error = 0; xfs_sb_mount_common(mp, sbp); /* * Initialise the XFS quota management subsystem for this mount * xfs_qm_newmount 调用 quota mangement 去 mount 901行 */ if (XFS_IS_QUOTA_RUNNING(mp)) &#123; error = xfs_qm_newmount(mp, &amp;quotamount, &amp;quotaflags); /*****/ if (error) goto out_rtunmount; &#125; else &#123; ASSERT(!XFS_IS_QUOTA_ON(mp)); /* * If a file system had quotas running earlier, but decided to * mount without -o uquota/pquota/gquota options, revoke the * quotachecked license. */ if (mp-&gt;m_sb.sb_qflags &amp; XFS_ALL_QUOTA_ACCT) &#123; xfs_notice(mp, &quot;resetting quota flags&quot;); error = xfs_mount_reset_sbqflags(mp); if (error) goto out_rtunmount; &#125; &#125; /* * Complete the quota initialisation, post-log-replay component. */ if (quotamount) &#123; ASSERT(mp-&gt;m_qflags == 0); mp-&gt;m_qflags = quotaflags; xfs_qm_mount_quotas(mp); &#125;... &#125; xfs_qm_mount_quotas根据 XFS_QM_NEED_QUOTACHECK(mp)的返回值决定是否做 quotacheck 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/* * This is called from xfs_mountfs to start quotas and initialize all * necessary data structures like quotainfo. This is also responsible for * running a quotacheck as necessary. We are guaranteed that the superblock * is consistently read in at this point. * * If we fail here, the mount will continue with quota turned off. We don't * need to inidicate success or failure at all. */xfs_qm_mount_quotas( struct xfs_mount *mp)&#123; int error = 0; uint sbf; /* * If quotas on realtime volumes is not supported, we disable * quotas immediately. */ if (mp-&gt;m_sb.sb_rextents) &#123; xfs_notice(mp, "Cannot turn on quotas for realtime filesystem"); mp-&gt;m_qflags = 0; goto write_changes; &#125; ASSERT(XFS_IS_QUOTA_RUNNING(mp)); /* * Allocate the quotainfo structure inside the mount struct, and * create quotainode(s), and change/rev superblock if necessary. */ error = xfs_qm_init_quotainfo(mp); if (error) &#123; /* * We must turn off quotas. */ ASSERT(mp-&gt;m_quotainfo == NULL); mp-&gt;m_qflags = 0; goto write_changes; &#125; /* * If any of the quotas are not consistent, do a quotacheck. */ if (XFS_QM_NEED_QUOTACHECK(mp)) &#123; error = xfs_qm_quotacheck(mp); if (error) &#123; /* Quotacheck failed and disabled quotas. */ return; &#125; &#125; /* * If one type of quotas is off, then it will lose its * quotachecked status, since we won't be doing accounting for * that type anymore. */ if (!XFS_IS_UQUOTA_ON(mp)) mp-&gt;m_qflags &amp;= ~XFS_UQUOTA_CHKD; if (!XFS_IS_GQUOTA_ON(mp)) mp-&gt;m_qflags &amp;= ~XFS_GQUOTA_CHKD; if (!XFS_IS_PQUOTA_ON(mp)) mp-&gt;m_qflags &amp;= ~XFS_PQUOTA_CHKD; &#125; XFS_IS_QUOTA_RUNNING(mp) 定义12345678//xfs_quota.h#define XFS_QM_NEED_QUOTACHECK(mp) \ ((XFS_IS_UQUOTA_ON(mp) &amp;&amp; \ (mp-&gt;m_sb.sb_qflags &amp; XFS_UQUOTA_CHKD) == 0) || \ (XFS_IS_GQUOTA_ON(mp) &amp;&amp; \ (mp-&gt;m_sb.sb_qflags &amp; XFS_GQUOTA_CHKD) == 0) || \ (XFS_IS_PQUOTA_ON(mp) &amp;&amp; \ (mp-&gt;m_sb.sb_qflags &amp; XFS_PQUOTA_CHKD) == 0)) XFS_QM_NEED_QUOTACHECK(mp) 的返回值 是根据 mp-&gt;m_sb.sb_qflags 的 flag 。flag 来自 xfs_sb 的 *from xfs 的 superblock。 123456xfs_sb_quota_to_disk( struct xfs_dsb *to, struct xfs_sb *from)&#123; __uint16_t qflags = from-&gt;sb_qflags;__be16 sb_qflags; /* quota flags */ xfs_qm_quotacheck最后调用的 quotacheck 函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114/* * Walk thru all the filesystem inodes and construct a consistent view * of the disk quota world. If the quotacheck fails, disable quotas. */ xfs_qm_quotacheck( xfs_mount_t *mp)&#123; int done, count, error, error2; xfs_ino_t lastino; size_t structsz; uint flags; LIST_HEAD (buffer_list); struct xfs_inode *uip = mp-&gt;m_quotainfo-&gt;qi_uquotaip; struct xfs_inode *gip = mp-&gt;m_quotainfo-&gt;qi_gquotaip; struct xfs_inode *pip = mp-&gt;m_quotainfo-&gt;qi_pquotaip; count = INT_MAX; structsz = 1; lastino = 0; flags = 0; ASSERT(uip || gip || pip); ASSERT(XFS_IS_QUOTA_RUNNING(mp)); xfs_notice(mp, &quot;Quotacheck needed: Please wait.&quot;); /* * First we go thru all the dquots on disk, USR and GRP/PRJ, and reset * their counters to zero. We need a clean slate. * We don&apos;t log our changes till later. */ if (uip) &#123; error = xfs_qm_dqiterate(mp, uip, XFS_QMOPT_UQUOTA, &amp;buffer_list); if (error) goto error_return; flags |= XFS_UQUOTA_CHKD; &#125; if (gip) &#123; error = xfs_qm_dqiterate(mp, gip, XFS_QMOPT_GQUOTA, &amp;buffer_list); if (error) goto error_return; flags |= XFS_GQUOTA_CHKD; &#125; if (pip) &#123; error = xfs_qm_dqiterate(mp, pip, XFS_QMOPT_PQUOTA, &amp;buffer_list); if (error) goto error_return; flags |= XFS_PQUOTA_CHKD; &#125; do &#123; /* * Iterate thru all the inodes in the file system, * adjusting the corresponding dquot counters in core. */ error = xfs_bulkstat(mp, &amp;lastino, &amp;count, xfs_qm_dqusage_adjust, structsz, NULL, &amp;done); if (error) break; &#125; while (!done); /* * We&apos;ve made all the changes that we need to make incore. Flush them * down to disk buffers if everything was updated successfully. */ if (XFS_IS_UQUOTA_ON(mp)) &#123; error = xfs_qm_dquot_walk(mp, XFS_DQ_USER, xfs_qm_flush_one, &amp;buffer_list); &#125; if (XFS_IS_GQUOTA_ON(mp)) &#123; error2 = xfs_qm_dquot_walk(mp, XFS_DQ_GROUP, xfs_qm_flush_one, &amp;buffer_list); if (!error) error = error2; &#125; if (XFS_IS_PQUOTA_ON(mp)) &#123; error2 = xfs_qm_dquot_walk(mp, XFS_DQ_PROJ, xfs_qm_flush_one, &amp;buffer_list); if (!error) error = error2; &#125; error2 = xfs_buf_delwri_submit(&amp;buffer_list); if (!error) error = error2; /* * We can get this error if we couldn&apos;t do a dquot allocation inside * xfs_qm_dqusage_adjust (via bulkstat). We don&apos;t care about the * dirty dquots that might be cached, we just want to get rid of them * and turn quotaoff. The dquots won&apos;t be attached to any of the inodes * at this point (because we intentionally didn&apos;t in dqget_noattach). */ if (error) &#123; xfs_qm_dqpurge_all(mp, XFS_QMOPT_QUOTALL); goto error_return; &#125; /* * If one type of quotas is off, then it will lose its * quotachecked status, since we won&apos;t be doing accounting for * that type anymore. */ mp-&gt;m_qflags &amp;= ~XFS_ALL_QUOTA_CHKD; mp-&gt;m_qflags |= flags;&#125;]]></content>
      <tags>
        <tag>kernel</tag>
        <tag>filesystem</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[japanese-redhat]]></title>
    <url>%2F2018%2F09%2F11%2F10-japanese-redhat%2F</url>
    <content type="text"><![CDATA[这是我在 redhat 工作时所用的模板，在这记录一下 开头ご利用ありがとうございます。レッドハットサポートの杜が承(うけたまわ)ります。 今回は技術的な新規のお問い合わせでしょうか？ 确认订阅それでははじめにご契約状況を確認致します。アカウント番号もしくはカスタマーポータルへのログイン ID をお願いします。/を伺ってよろしいでしょうか。 – それでは確認致しますので少々お待ち下さい。 お待たせしました。確認のため、ご登録いただいている会社名と担当者様、およびご質問者様のお名前をお願いします。 – ありがとうございます。ご契約の確認が取れましたので、ご質問を承ります。 アカウント番号 不对お待たせしました。恐れ入りますがお知らせいただいたアカウント番号を確認することができませんでした。今一度アカウント番号を確認させていただけますか？ こちらは現在登録されていない番号のようです。恐れ入りますが、他のアカウント番号やログイン ID はございますでしょうか？ 什么是 アカウント番号サブスクリプション証書がございましたらコントラクト番号や照会番号といった番号をお知らせいただいても確認が可能ですが、そのような証書はお手元にございませんでしょうか？ 公司名人名不对恐れ入りますが、このアカウント番号に登録されている会社名はお客様からご提供な会社名と違いますので、ご登録情報を再度ご確認いただけませんでしょうか。 转 CSそういったお話はオプション 3 番のカスタマーサービスで承っております。カスタマーサービスへ転送いたしますので、 少々お待ちください。 没听懂すみません、よく聞き取れなかったのでもう一度よろしいですか？ 再等待一会お待たせしており申し訳ございません。もう少々お待ちください。 链接それでは、xxx方法のドキュメントを公開しておりますので、そちらをご案内させていただいてもよいでしょうか。 搜索カスタマーポータルの右上の検索のアイコン(マーク)をクリックしてください。 それでは、いまから 6桁(けた)の数字をお伝えします。”417 183” です。こちらを検索いただくと『Red Hat Subscription-Manager を使用して』から始まる結果が見つかりますので、タイトルをクリックしてください。 直接给链接ナレッジのURLをお伝えしようと思いますがよろしいでしょうか？ https://access.redhat.com/solutions/123123：クロン /スラッシュ . ドット 拼写スペル A大文字 a小文字 没找到链接こちらで伺った情報を元にナレッジベースの既知事例を検索いたしましたが、該当するような既知事例は見受けられませ んでした。 给链接之后こちらのドキュメントの解決策のところに、一通りの登録手順の説明がございます。 お手数ではございますがこちらの文章をご一読いただいてシステム登録をお試しください。不明な点がありましたら改めてご連絡いただくか、エラー等が発生した場合はケースを起票いただいて出力結果を調査させていただきたいと思いますがよろしいでしょうか。 语言切换今カスタマーポータルの画面は日本語で表示されていますでしょうか。もしくは英語でしょうか。お客様の画面は今英語でしょうか、それとも日本語でしょうか。 开 caseお電話での解決が難しい問題かと思いますので、サポートケースの作成をお願いできますでしょうか。 そうしますと、恐れ入りますが、お電話でのご案内が難しい内容で、現在は操作ができない状況、ログなどいろいろ確認させていただく必要が考えられます。 類似のメッセージや問題は、確かに、弊社ナレッジにも御座います。しかしながら、お客様環境にて発生している事象が、全く同じ原因なのかを、電話で判断する事は出来ません。従いまして、資料を元に正しく確認をさせて頂いてもよいでしょうか。 什么是 caseケースは、何らかの問題が発生している場合、または発生している内容に関しての技術的なサポートを弊社のカスタマーポータルを介してお客様とやり取りする為の、Web UI のツールでございます。 ケースを作成して頂きますと、担当した弊社エンジニアとのやり取りを開始する事が可能となり、弊社からお客様に対して技術的なサポートを御提供する事が可能となります。電話等では、詳細な技術サポートを提供する事は難しい場合もあり、また、お互いに認識の違いが発生しやすいことも考えられます。この様な事を避ける意味でも、ケースをご利用いただく事をお願いしております。 怎么开 case今弊社のカスタマーポータルにログインされておりますでしょうか。 カスタマーポータルの左上に「サポートケースを管理」というリンク(link)がございますので、そちらをクリックしてください。 そうしますと、画面右側に「サポートケースを作成する」という青いボタンが出てきますのでそちらをクリックしてください。 サポートケースの作成画面が表示されましたら、ご質問内容や製品のバージョンなどの情報を入力いただき「送信する」のボタンをクリックいただければ、担当者が調査を行ったうえでご連絡いたします。 sosreportsosreport とは、システムから設定と診断情報を取得するツールです。たとえば、実行しているカーネルのバージョン、ロードしたモジュール、そしてシステムおよびサービスの設定ファイルを取得します。 sosreport を実行するには、sos パッケージがインストールされている必要があります。パッケージはデフォルトグループに含まれており、意図的に除外しない限りシステムには自動的にインストールされます。 sosreport コマンドが完了すると、/tmp (RHEL6 以前) または /var/tmp (RHEL7 以降) の下に圧縮ファイルが生成されます。バージョンが異なると使用する圧縮スキームが異なります (gz、bz2、または xz)。作成されたファイルを (通常はケースに添付して) サポートチームにご提供ください。 催 case开了 CASE確認のために、ケース番号を伺ってよろしいでしょうか。お待たせいたしました。念のためにケースのタイトルを伺ってよろしいでしょうか。 等待申し訳ございませんが、XX エンジニアはただいま調査させていただいておりますので、ケースの更新をいま暫くお待ちください。 截止时间このケースの回答時間をチェックいたしましたところ、少なくともOOまでには何らかのご連絡（回答）をさせて頂く予定となっております。 SLA応答時間の定義に基づいて対応しておりますので、恐れ入りますが、何時何分までにコメントするという事は確約出来ませんが、お客様からの要望があった事を申し伝えておきます。 找case ower 的ただいま担当者が対応可能か確認いたしますので少々お待ちください。 能转お待たせいたしました。担当者が対応可能でしたのでお電話転送いたします。 不能转お待たせいたしました。申し訳ございませんが、ただいま担当者が席を外しておりますので(or 別のお電話に出ておりますので or 本日不在(ふざい)ですので) 担当者とお話いただくことができません。お手数ですが、サポートケースにご質問内容を記載(きさい)いただけませんでしょうか。」 回电话担当者から折り返しのお電話をさせていただきます。お名前と電話番号をお教えください。すぐに折り返しのお電話ができるかお約束はできませんが、なるべく早くお電話するよう担当者に伝えます。 重大度重大度については本番環境で業務影響が発生している場合に重大度2以上となり、そうでない場合には重大度は3以下に設定いただけますようお願いいたします。(重大度の定義は青いはてなのマークをクリックすることでご確認いただけます。) CVECommon Vulnerabilities and Exposures identifiers (“CVE name” または単純に “CVE”) は、情報セキュリティ問題 (特に、セキュリティの脆弱性および問題) について、ベンダーに依存しない標準となる名称を提供します。Red Hat エラータ、他ベンダーのセキュリティ報告、バグ追跡システムなどの、セキュリティ関連のやりとりに CVE が使用されます。システムおよびネットワーク管理者は、特定の CVE 名に対してシステムにパッチがあたっていることを確認するよう依頼されます。 脆弱性については弊社では CVE Database を提供しており、ご利用の製品に影響があるかどうかをお客様ご自身(じしん)で調べていただくことができます。 CVE-xxxx-xxxx はお客様がご利用の RHEL7 には影響はございません。 字符类型RHEL は UTF-8 でのみ動作確認(テスト)されています。他の文字コードはサポートされません。 文字コードに euc-jp や shift-jis をご使用いただくことは技術的には可能ですが、euc-jp や shift-jis を使用していることによって発生したと思われる問題についてはサポートすることができません。 L3-ONLYお客様がお持ちのご契約は L3-only (エルスリーオンリー) のご契約です。L3-only の場合、技術的なご質問は弊社ではなくサブスクリプションを購入されたOEM (オーイーエム) ベンダー様の窓口 (まどぐち) で行 (おこな) っていただく必要がございます。恐れ入りますが、サブスクリプションを購入されたベンダー様の窓口までお問い合わせいただけますでしょうか。 Dell 様や HP 様などのハードウェアベンダー様であることが一般的です。ハードウェアと一緒に L3-only のサブスクリプションを購入されていることが多いです。 お客様がどちらの会社と契約されているかは弊社ではわからないため、お客様ご自身(じしん)でご確認いただく必要がございます。 没有订阅大変申し訳ございませんが、こちらは技術的な質問を承る窓口ですので、ご案内ができません。ご購入いただいた時のご担当者様へ確認いただくか、この電話のオプション３番の窓口へお問い合わせいただければと存じます。 # CS への誘導 看系统版本システムに保存されているレッドハットリリースファイルでご確認いただけます。はい、フルパスで申し上げます。スラ、エトセ (/etc。 スラ、レッドハット、ハイフン (/redhat-。リリース (release) ですバージョン 7 ですね。 为什么不能电话解决「調査で利用する資料をファイルで提供いただく必要がありますので、引き続き電話で対応することができません」「電話では、聞き取りミスや漏れが起こる可能性が残りますので、情報を正確にヒアリングすることは困難です」 电话支持范围お電話でご案内できる範囲としてはですね、例えば、何か特定のエラーメッセージが出てるということであれば、そのエ ラーメッセージについて、ナレッジベースの既知事例、検索して、ご案内ということができるんです。 RHEL5结尾ご質問は以上でよろしいでしょうか？//// 他に何かご質問はございますか？ ケース上でご連絡お待ちしております。担当の曾が承りました、ご利用ありがとうございました。 承知致しました。今回は担当の杜が承りました。ご利用、ありがとうございました. 字母及符号数字および記号の読み方 (参考 : NATO フォネティックコード)A: エー : アルファ (Alpha) のエー, アクセス(access), アカウント(account), アプリ(application)B: ビー : ブラボー (Bravo) のビー, バット(bat), ボールペン(ballpen), べースボール(baseball), ブック(book) C: シー : チャーリー (Charlie) のシー, チャイナ(China),C 言語, ケース(case)D: デー : デルタ (Delta) のデー, データ(Data), デフォルト(default), デバイス(device)E: イー : エコー (Echo) のイー, エンジニア(engineer), email, エラー(Error)F: エフ : フォックストロット (Foxtrot) のエフ, フランス(France), ファイル(file), フレンド(friend)G: ジー : ゴルフ (Golf) のジー, ゴルフ(golf), ゲーム(game)H: エイチ : ホテル (Hotel) のエイチ, ハード(hard), ホスト(host), ホテル(hotel)I: アイ : インディア (India) のアイ, インストール(install), イメージ(image), インフォ(info), インプット(input) J: ジェイ : ジュリエット (Juliet) のジェイ, ジャパン(japan), ジャバ(java)K: ケイ : キロ (Kilo) のケイ, カーネル(kernel), キーボード(keyboard), キーワード(keyword)L: エル : リマ (Lima) のエル, リナックス(Linux), リスト(list), ライン(line)M: エム : マイク (Mike) のエム, メモリ(memory), メール(mail), メモ(memo), メニュー(menu) N: エヌ : ノベンバー (November) のエヌ, ネットワーク(network), ニュース(news), ノート(note) O: オー : オスカー (Oscar) のオー, オーエス(os), オプション(option),オープン(open)P: ピー : パパ (Papa) のピー, プリント(print), パッケージ(package), パラメーター(parameter)Q: キュー : ケベック (Quebec) のキュー, QR コード(QR code), クエスチョン(question), クウォーター(quota)R: アール : ロミオ (Romeo) のアール, レッドハット(RedHat), リブート(reboot), ルート(root), リモート(remote), レスキ ュー(rescue)S: エス : シエラ (Sierra) のエス, サービス(service), ソフトウェア(software), ソリューション(solution), サポート (support)T: テー : タンゴ (Tango) のティー, テスト(test), 東京(tokyo), テキスト(text)U: ユー : ユニフォーム (Uniform) のユー, USA, USB, ユーザー(user)V: ブイ : ビクター (Victor) のブイ, バージョン(version), ベンダー(vendor)W: ダブリュー : ウィスキー (Whiskey) のダブリュー, ワード(word), ウェブ(web),ウィンドウ(window)X: エックス : エックス線 (X-Ray) のエックス, X 線、XYZ、X ウィンドウ(X Window)Y: ワイ : ヤンキー (Yankee) のワイ, イエス(yes), yum, イエロー(yellow), ヨガ(yoga)Z: ゼット : ズールー (Zulu) のゼロ, ゼロ(zero), ゾーン(zone)1: いち2: に3: さん4: よん5: ご6: ろく7: なな8: はち9: きゅう0: ぜろ/: スラッシュ .: ドット:: コロン-: ハイフン+: プラス_: アンダーバー (アンダースコア)*: アスタリスク|: 縦棒 (パイプ記号)~: チルダ@: アットマーク!: エクスクラメーション (びっくりマーク)?: くエスチョンマーク (はてなマーク、はてな記号) \: バックスラッシュ“: ダブルクオート (二重かっこ)‘: シングルクオート (一重かっこ)`: バッククオート ;: セミコロン #: シャープ$: ドル記号%: パーセント^: ハット&amp;: アンパサンド (アンド記号) +: プラス=: イコール( ): かっこ (丸かっこ){ }: 中かっこ (弓かっこ)[ ]: 大かっこ (角かっこ)&lt; &gt;: 山かっこ1 ついたち 2 ふつか9 ここのか 10 とおか3 みっか11 じゅういちにち5 いつか12 じゅうににち 13 じゅうさんにち14 じゅうよっか18 じゅうはちにち 22 にじゅうににち 25 にじゅうごにち 28 にじゅうはちにち1~10:15 じゅうごにち 16 じゅうろくにち 17 じゅうしちにち 19 じゅうくにち 20 はつか 21 にじゅういちにち24 にじゅうよっか27 にじゅうしちにち23 にじゅうさんにち 26 にじゅうろくにち 29 にじゅうくにち4 よっか6 むいか7 なのか8 ようか30 さんじゅうにち 31 さんじゅういちにち ひとつ、ふたつ、みっつ、よっつ、いつつ、むっつ、ななつ、やっつ、ここのつ、とおつ]]></content>
      <tags>
        <tag>japanese</tag>
        <tag>redhat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VFS 虚拟文件系统]]></title>
    <url>%2F2018%2F09%2F10%2F9-VFS%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[前言虚拟文件系统作为内核的子系统为用户空间程序和真正的多个文件系统直接提供了一个接口。简单来说。系统调用先和 VFS 交互，然后 VFS 提供的通用接口在被各个文件系统来实现。 通用文件系统接口虚拟文件系统，一个胶水层，位于内核的底层和用户层之间。它提供了各种抽象数据结构来表示文件和inode，而真实文件系统的实现必须填充这些结构，使得应用程序无需考虑底层文件系统，总是可以使用同样的接口访问和操作文件。在 VFS 和 内核 看来，底层的文件系统都是相同的，他们都支持文件、目录、Inode等概念。 进程调用系统调用 write(),系统调用 调用 VFS 中的通用接口 sys_wirte(),通用接口被底层真正的文件系统一一实现。 UNIX 文件系统VFS 文件系统的结构不在磁盘中真正存在，在系统启动时装载到内存中，VFS 结构与 EXT 文件系统相似，因为 EXT 文件系统是 linux 的原生文件系统。都有 file,directory,inode。 Unix 文件系统相关概念： file：文件对象主要是对进程而言，对应的操作函数基本和常见的系统调用一样。 Inode：一个 Inode 对应一个文件，系统查找文件其实找的是 Inode，找到 Inode 后，通过对应关系去 data block 找到真正数据，Inode 中除了数据本身，文件的其他所有信息都包含，例如权限，访问时间，link等。 surperblock: 文件系统的元数据，在mount 时，从 disk 的 superblock 读取到内存的 surperblock 对象中。 dentry cache: 系统通过 Inode 在磁盘中找到文件的过程需要耗费大量时间，所以 VFS 引入了 dentry 对象来存放路径缓存，例如/mnt/dir/test.txt，其中/ 、mnt、dir、text.txt 都是一个 dentry 对象。有了缓存后，系统只需要在磁盘中找到 test.txt 的 inode 位置。 vfsmount，file_system_type 挂载点以及文件系统属性。 fs_struct 和 file 偏向于进程相关的对象。 VFS 的对象和数据结构Superblock12345678910111213141516171819202122232425262728293031//from &lt;linux/fs.h&gt;// 在挂载时读入初始化struct super_block &#123; struct list_head s_list; /* list of all superblocks */ ... struct super_operations s_op; /* superblock methods */ struct list_head s_inodes; struct super_operations &#123;struct inode *(*alloc_inode)(struct super_block *sb); void (*destroy_inode)(struct inode *);void (*dirty_inode) (struct inode *);int (*write_inode) (struct inode *, int);void (*drop_inode) (struct inode *);void (*delete_inode) (struct inode *);void (*put_super) (struct super_block *);void (*write_super) (struct super_block *);int (*sync_fs)(struct super_block *sb, int wait); int (*freeze_fs) (struct super_block *);int (*unfreeze_fs) (struct super_block *);int (*statfs) (struct dentry *, struct kstatfs *);int (*remount_fs) (struct super_block *, int *, char *);void (*clear_inode) (struct inode *);void (*umount_begin) (struct super_block *);int (*show_options)(struct seq_file *, struct vfsmount *);int (*show_stats)(struct seq_file *, struct vfsmount *);...&#125;sb-&gt;s_op-&gt;write_super(sb);// C 不是面向对象的，需要这种方式来调用函数。但其实 VFS 中大多数概念都是面向对象的思想来实现的。 Inode 文件系统不管实际是否有 Inode ，想在 linux 中使用，必须将 Inode 虚拟化出来装载到内存中。 有的文件系统 没有 i_atime i_mtime, i_atime 概念，可以直接填写为 NULL，或者不往磁盘里刷脏。 可以看到 inode 的一些函数中传参都是 dentry，意味着在获取 Inode 之前，系统已经拿到对应的 dentry，也就是先有 dentry，再去找 inode。1234567891011//from &lt;linux/fs.h&gt;struct inode_operations &#123;int (*create) (struct inode *,struct dentry *,int, struct nameidata *);struct dentry * (*lookup) (struct inode *,struct dentry *, struct nameidata *); int (*link) (struct dentry *,struct inode *,struct dentry *);int (*unlink) (struct inode *,struct dentry *);int (*symlink) (struct inode *,struct dentry *,const char *);int link(struct dentry *old_dentry, struct inode *dir,struct dentry *dentry)//Invoked by the link() system call to create a hard link of the file old_dentry in the directory dir with the new filename dentry....&#125; dentry dentry：目录项是描述文件的逻辑属性，只存在于内存中，并没有实际对应的磁盘上的描述，更确切的说是存在于内存的目录项缓存，为了提高查找性能而设计。注意不管是文件夹还是最终的文件，都是属于目录项，所有的目录项在一起构成一颗庞大的目录树。 一个有效的dentry结构必定有一个inode结构，这是因为一个目录项要么代表着一个文件，要么代表着一个目录，而目录实际上也是文件。所以，只要dentry结构是有效的，则其指针d_inode必定指向一个inode结构。 dentry 有三个状态： used：正在被用的，通过d_count记录用户数量，不能被回收。 unused：没有被用的，d_count是0，对应 Inode 是有效的。可以被回收 negative：对应 Inode 无效，被删除了，可以被回收。及时无效也不会立即被删除，因为同样有用，告知系统文件不存在。 dentry cache 的存放： used 通过i_dentry属性放在链表中。 还有一个双向链表存放最近使用的dentry(unused and negative),链表头尾决定新旧程度，以及回收顺序。 hash 表dentry_hashtable 和 hash 函数d_lookup()，来定位要查找的 dentry。具体实现很复杂，详细请看相关文档。 12345678910111213141516171819//from &lt;linux/fs.h&gt;struct dentry &#123; atomic_t d_count; unsigned int d_flags;spinlock_t d_lock;int d_mounted;struct inode *d_inode; /* associated inode */ ...&#125;struct dentry_operations &#123;int (*d_revalidate) (struct dentry *, struct nameidata *);int (*d_hash) (struct dentry *, struct qstr *);int (*d_compare) (struct dentry *, struct qstr *, struct qstr *); int (*d_delete) (struct dentry *);void (*d_release) (struct dentry *);void (*d_iput) (struct dentry *, struct inode *);char *(*d_dname) (struct dentry *, char *, int);&#125;; file 文件对象对应进程打开的文件，不是磁盘中的文件。 通过 open()系统调用创建，close()删除。 文件对象函数是我们那些常见的系统调用的基础，read（）write（）其实调用的就是 file 的函数。12345678910111213struct file_operations &#123; struct module *owner;ssize_t (*read) (struct file *, char __user *, size_t, loff_t *); ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *); ssize_t (*aio_read) (struct kiocb *, const struct iovec *,unsigned long, loff_t);ssize_t (*aio_write) (struct kiocb *, const struct iovec *,unsigned long, loff_t);int (*readdir) (struct file *, void *, filldir_t);long (*unlocked_ioctl) (struct file *, unsigned int, unsigned long); long (*compat_ioctl) (struct file *, unsigned int, unsigned long); int (*mmap) (struct file *, struct vm_area_struct *);int (*open) (struct inode *, struct file *);int (*flush) (struct file *, fl_owner_t id);int (*release) (struct inode *, struct file *);int (*fsync) (struct file *, struct dentry *, int datasync);int (*aio_fsync) (struct kiocb *, int datasync);int (*fasync) (int, struct file *, int);int (*lock) (struct file *, int, struct file_lock *); files_struct 这是一个进程相关的对象，进程打开的文件和文件描述符相关的信息都在里面。 fd_array 指向打开文件的链表。123456789101112131415161718//from &lt;linux/fdtable.h&gt;.struct files_struct &#123; /* * read mostly part */ atomic_t count; struct fdtable __rcu *fdt; struct fdtable fdtab; /* * written part on a separate cache line in SMP */ spinlock_t file_lock ____cacheline_aligned_in_smp; int next_fd; unsigned long close_on_exec_init[1]; unsigned long open_fds_init[1]; struct file __rcu * fd_array[NR_OPEN_DEFAULT];&#125;; 进程如何找到打开的文件，通过文件描述符，file_struct,dentry,inode。]]></content>
      <tags>
        <tag>kernel</tag>
        <tag>filesystem</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 分区和文件系统结构]]></title>
    <url>%2F2018%2F08%2F19%2F8-linux%E5%88%86%E5%8C%BA%E5%92%8C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[前言本篇文章总结一下磁盘分区以及文件系统的结构，以及文件的 inode 、文件描述符(file descriptor)的用法和概念。 磁盘分区关于磁盘的物理结构不做太多描述，主要讲述分区的细节，以及第一个扇区上的引导。 磁盘物理结构： 磁头（Head）：代表有多少层盘面 磁道（Track） 柱面（Cylinder）：每一个盘面上有多少圈磁道 扇区（Sector）：一圈磁道上有很多扇区，每个扇区有512字节，第一个扇区称为引导扇区。 fdisk 可以看到每一块盘上述结构的数量。fdisk 看到磁盘的大小 = （盘面 柱面 扇区 * 512bytes） 1.分区结构磁盘通过分区，可以实现多个文件系统，多个操作系统，快速的IO。物理上分区是通过柱面来进行分割的。目前最为广泛的还是MBR分区，但是 MBR 最大只支持2T 磁盘，且只支持4个主分区，所以未来将逐渐使用 GPT 分区。 MBR 分区MBR (Master Boot Record) 是指磁盘第一个扇区，包括引导程序、MBR分区表、MBR结束标志3部分构成，一共占用512个字节。 主引导程序(boot loader)，446字节，有grub(linux),LILO,BOOTMGR等，提供给用户可以启动的操作系统，每一个分区开头也有一个引导程序部分，通过主引导找到分区上的引导程序可以实现多系统。 分区表，64字节，每一个分区需要16个字节。MBR 只能有4个主分区，或者3+1扩展分区。 每一个分区表16字节中有4个字节来记录扇区号，每个分区最大支持2T，2^(48)512byte=2T，通过4K大小的扇区可以解决。 结束标志2字节，55aa = (0101 0101 1010 1010 ) GPT 分区GPT 分区（GUID Partition Table）全称全局唯一标识分区表，是EFI标准一部分，用来代替bios以及MBR。GPT分区使用64bit记录逻辑地址，8 ZiB个扇区大小的磁盘。 GPT 使用逻辑区块地址（LBA 512字节一个，一个扇区大小）取代了早期的CHS寻址方式。在非传统硬盘上，例如SSD 有可能LBA 是2K/4K。 传统 MBR 信息存储于LBA 0，引导启动程序也在这里，GPT 头存储于LBA 1，接下来才是分区表本身。 GPT 分区表大小不是固定的，64位Windows操作系统使用16,384字节（或32扇区）作为GPT分区表(最多128个分区=16,384/128)， 接下来的LBA 34是硬盘上第一个分区的开始。 文件系统1.文件系统结构 Boot Sector ：每个分区最前面都有一个引导区，被主引导找到。 Super Block(超级块): 存放文件系统的结构信息, 说明各部分的大小. super_block[8], 可加载8个文件系统 Inode Bitmap(i节点位图): 记录i节点的使用情况, 1bit代表一个i节点. s_imap[8], 占用8个块, 可表示8191个i节点情况 Block Bitmap(逻辑块位图): 记录数据区的使用情况, 1bit代表一个盘块(block). s_zmap[8], 占用8个块, 最大支持64M的硬盘 Inode(i节点) Table: 存放inode 号和数据块的对应关系。每个文件或目录名唯一对应一个i节点, 在i节点中, 储存 id信息, 文件长度, 时间信息, 实际数据所在位置等等。目录文件的data block 中存放的是目录下文件名和对应的 inode 号。 2.inode 如何找到文件。在Linux中，我们通过解析路径，根据沿途的目录文件来找到某个文件。目录中的条目除了所包含的文件名，还有对应的inode编号。 当我们输入$cat /var/test.txt时，Linux 将在根目录文件中找到 var 这个目录文件的inode编号，然后根据 inode 合成 var 的数据。随后，根据 var 中的记录，找到 text.txt 的 inode 编号，沿着 inode 中的指针，收集数据块，合成 text.txt 的数据。 整个过程中，会参考三个inode： 根目录文件的 inode：2，用于找到 var 的 inode id var 目录文件的 inode：10747905，用于找到 test.txt 的 inode id text.txt 文件的 inode： 10749034，用于找到 data blocks 3.File descriptor对于linux而言，所有对设备和文件的操作都使用文件描述符来进行的。文件描述符是一个非负的整数，它是一个索引值，指向内核中每个进程打开文件的记录表。当打开一个现存文件或创建一个新文件时，内核就向进程返回一个文件描述符；当需要读写文件时，也需要把文件描述符作为参数传递给相应的函数。通常，一个进程启动时，都会打开3个文件：标准输入、标准输出和标准出错处理。这3个文件分别对应文件描述符为0、1和2（宏STD_FILENO、STDOUT_FILENO和STDERR_FILENO）。 每一个文件描述符会与一个打开文件相对应，同时，不同的文件描述符也会指向同一个文件。相同的文件可以被不同的进程打开也可以在同一个进程中被多次打开。系统为每一个进程维护了一个文件描述符表，该表的值都是从0开始的，所以在不同的进程中你会看到相同的文件描述符，这种情况下相同文件描述符有可能指向同一个文件，也有可能指向不同的文件。具体情况要具体分析，要理解具体其概况如何，需要查看由内核维护的3个数据结构。 进程级的文件描述符表 系统级的打开文件描述符表 文件系统的i-node表 由于进程级文件描述符表的存在，不同的进程中会出现相同的文件描述符，它们可能指向同一个文件，也可能指向不同的文件。两个不同的文件描述符，若指向同一个打开文件句柄，将共享同一文件偏移量。因此，如果通过其中一个文件描述符来修改文件偏移量，那么从另一个文件描述符中也会观察到变化，无论这两个文件描述符是否属于不同进程，还是同一个进程，情况都是如此。 进程通过文件描述符、文件系统表（打开的文件句柄 ） 以 及 i-node之间的关系找到对应文件。 彩蛋：df 是怎么计算出来的df Result = firstblock + superblocks + gdblocks + (2 + inode_blocks_per_group) * groups + journal_length 1234567891011121314151617181920212223242526tune2fs -l /dev/vdb1| grep &quot;Block count:&quot;Block count: 524288tune2fs -l /dev/vdb1 | grep &quot;First block:&quot;First block: 0dumpe2fs /dev/vdb1 | grep superblock | wc -ldumpe2fs 1.42.9 (28-Dec-2013)6dumpe2fs /dev/vdb1 | grep &quot;Group descriptors&quot; | wc -ldumpe2fs 1.42.9 (28-Dec-2013)6dumpe2fs /dev/vdb1| grep ^Group | wc -ldumpe2fs 1.42.9 (28-Dec-2013)17tune2fs -l /dev/vdb1 | grep &quot;Inode blocks per group:&quot;Inode blocks per group: 512dumpe2fs /dev/vdb1 | grep &quot;Journal length&quot;dumpe2fs 1.42.9 (28-Dec-2013)Journal length: 163840+6+6+（2+512）*17+16384=2513425134是这些东西占的块数 *4096byte/1024=100536KB 和df 差的差不多]]></content>
      <tags>
        <tag>storage</tag>
        <tag>filesystem</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LUKS磁盘加密]]></title>
    <url>%2F2018%2F08%2F13%2F7-LUKS%E7%A3%81%E7%9B%98%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[前言LUKS （Linux Unified Key Setup）是 Linux 硬盘加密的标准。通过提供标准的磁盘格式，它不仅可以促进发行版之间的兼容性，还可以提供对多个用户密码的安全管理。 与现有解决方案相比，LUKS 将所有必要的设置信息存储在分区信息首部中，使用户能够无缝传输或迁移其数据。 只有在开启映射的时候需要密码，在映射分区的挂载和使用是不需要密码的。 加密后分区不能直接挂载，只能挂载映射分区，一般用来防止磁盘在其他机器上访问。 支持 LVM，LVM 和 dm-crypt 都是基于 Linux 内核的 device mapper 机制。 LUKS 的使用步骤123456789101112131415161718192021// 1.正常分区$ parted / fstab // 2.对为初始化的分区进行加密，输入密码或者使用文件内容加密,可选加密方式$ cryptsetup luksFormat /dev/sdc1（/dev/VG/LV） $ cryptsetup --cipher aes-xts-plain64 --key-size 512 --hash sha512 --iter-time 10000 luksFormat /dev/sda2 //密码放在文件内 $ cryptsetup luksFormat DEV /root/random_data_keyfile1 //增加密码 $ cryptsetup luksAddKey /dev/sdc1 /passwd_txt// 3.打开加密的分区，将其映射到一个不加密的分区上 /dev/mapper/luks-uuid分区$ cryptsetup luksOpen /dev/sdc1 luks--$(cryptsetup luksUUID /dev/sda3)// 4.格式化分区并挂载$ mkfs.ext4 /dev/mapper/test// 5.umount 后 可以进行 取消映射$ cryptsetup luksClose test 开机自动识别加密磁盘/etc/crypttab 文件记录映射内容以及解密密码所在文件。 12345$ cat /etc/crypttab test /dev/sdc1 /passwd_txtxxx /dev/sda15 /root/keyfile luks// (映射名，分区，key文件位置，最后一列就是'luks') 根分区自动识别需要在 grub 中声明 LUKS 加密的磁盘以及解密文件 12345678//rhel6$ sed -i "/^\s*kernel/s,$, rd_LUKS_UUID=$(cryptsetup luksUUID /dev/sda3)," /boot/grub/grub.conf // rhel7$ sed -i "/^GRUB_CMDLINE_LINUX/s,\"$, rd.luks.uuid=$(cryptsetup luksUUID /dev/sda3)\"," /etc/default/grub $ grub2-mkconfig &gt;/etc/grub2.cfg $ dracut -f 忘记密码怎么办？ 设置多个密码的情况，可以尝试找到其他密码 123456789101112$ blkid -t TYPE=crypto_LUKS -o device/dev/vdb1$ cryptsetup luksDump /dev/vdb1 | grep Key.SlotKey Slot 0: ENABLEDKey Slot 1: DISABLEDKey Slot 2: DISABLEDKey Slot 3: DISABLEDKey Slot 4: DISABLEDKey Slot 5: DISABLEDKey Slot 6: DISABLEDKey Slot 7: DISABLED 如果磁盘当前可用，可以使用 root 用户通过master key增加新的密码 123456789101112131415161718//首先找到设备，使用lsblk, findmnt, df, mount, or /etc/fstab确认$ dmsetup ls --target cryptvdc-decrypted (253, 2)luks-ec013cf7-ad72-4dcf-8a1e-0548016a3e2c (253, 1)//找到 master key ,在第五列$ dmsetup table &lt;MAP&gt; --showkeys//通过master key增加新的密码,需要先转换成binary$ lsblk | grep -B1 luks-ec013cf7-ad72-4dcf-8a1e-0548016a3e2c └─vdb1 252:17 0 1023M 0 part └─luks-ec013cf7-ad72-4dcf-8a1e-0548016a3e2c 253:1 0 1021M 0 crypt /cryptstor$ cryptsetup luksAddKey /dev/vdb1 --master-key-file &lt;(dmsetup table --showkey /dev/mapper/luks-ec013cf7-ad72-4dcf-8a1e-0548016a3e2c | awk &apos;&#123;print$5&#125;&apos; | xxd -r -p)Enter new passphrase for key slot:Verify passphrase:$ cryptsetup luksDump /dev/vdb1 | grep ENABLEDKey Slot 0: ENABLEDKey Slot 1: ENABLED]]></content>
      <tags>
        <tag>storage</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内核同步的实现]]></title>
    <url>%2F2018%2F08%2F12%2F6-%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[原子操作内核提供了两组原子操作的接口，一组对整数进行操作，一组对单独的位进行操作。 1.原子的整数操作整数的原子操作只对atomiac_t 类型的数据进行处理，好处是让原子函数只接收atomic_t类型的数据，也保证了该类型的数据不传递给其他函数。另一个好处是使得原子操作最终接收到的是内存地址。123456789101112131415161718//atomic_t 定义在 &lt;linux/types.h&gt;:typedef struct &#123; volatile int counter;&#125; atomic_t;//所有的原子整数操作都声明在 &lt;asm/atomic.h&gt;ATOMIC_INIT(int i) //初始化atomic_t u = ATOMIC_INIT(0); /*初始化并赋值 *///这两个可以实现计数器void atomic_inc(atomic_t *v) //Atomically add one to v. void atomic_dec(atomic_t *v) //Atomically subtract one from v.int atomic_read(atomic_t *v) //Atomically read the integer value of v. 可以用来转换成 intvoid atomic_set(atomic_t *v, int i) //Atomically set v equal to i.//执行一个操作然后返回结果int atomic_dec_and_test(atomic_t *v) //减1 如果是0 返回TRUE 原子操作通常是内联函数，通常通过内嵌汇编指令实现。如果函数本身就是原子的，往往被定义为一个宏。读操作本身就是一个原子操作，所以atomic_read()就是一个宏。 64位的原子变量atomic_t 和atomic64_t 由于移植性原因，atomic_t的大小无法在体系机构间改变，要使用64的原子变量的话就需要使用atomic64_t。和atomic_t 一样,atomic64_t也有一样的原子操作函数。 2.原子位操作 位操作函数是对普通的内存地址进行操作的，参数是一个指针和一个位号。 位操作是对普通的指针进行的，所以没有特定的数据类型。只要指针指向了你想要的数据，就可以进行操作。 原子位操作函数 123456789void set_bit(int nr, void *addr) #Atomically set the nr-th bit starting from addr.set_bit(0, &amp;word); # 设置 word 的第0位void clear_bit(int nr, void *addr) #Atomically clear the nr-th bit starting from addr.void change_bit(int nr, void *addr) #Atomically flip the value of the nr-th bit starting from addr.int test_and_set_bit(int nr, void *addr) #Atomically set the nr-th bit starting from addr and return the previous value.int test_and_clear_bit(int nr, void *addr) #Atomically clear the nr-th bit starting from addr and return the previous value.int test_and_change_bit(int nr, void *addr) #Atomically flip the nr-th bit starting from addr and return the previous value.int test_bit(int nr, void *addr)# Atomically return the value of the nr￾th bit starting from addr. 自旋锁（spin lock）并不是所有的临界区只处理变量的加减，有的临界区需要处理复杂的数据结构，且跨越多个函数。例如将一个数据结构的数据拿出并转换格式和解析放到另外一个数据结构中。这时候就需要锁来提供保护。自旋锁是内核中最常见的，自旋锁最多被一个运行线程持有，等待的线程会一直处于自旋的状态（loops— spins—waiting）。 信号量：自旋的状态一直消耗 CPU，适合短时间的锁。另一种形式就是让后来的线程不循环等待，去执行其他代码。这样会带来开销，并进行2次上下文切换。 自旋锁的实现自旋锁的实现与体系结构相关，通过汇编实现。linux 的自旋锁是不可递归的。 12345678//体系结构相关代码 &lt;asm/spinlock.h&gt;//可用接口代码 &lt;linux/spinlock.h&gt;// 自旋锁的基本形式DEFINE_SPINLOCK(mr_lock);spin_lock(&amp;mr_lock);/* critical region ... */ spin_unlock(&amp;mr_lock); 中断处理程序可以使用自旋锁（也只可以使用自旋锁），当时在获取锁之前，一定要禁止本地中断(当前 CPU 的中断请求)，否则，中断会打断已经获取锁的内核代码，造成死锁。在不同 CPU 上不需要。 关于自旋锁和下半部，下半部会抢占进程上下文，需要在加锁的同时禁止下半部，同样中断也会抢占下半部，下半部获取锁后也需要禁止中断。tasklet 和 软中断不会抢占另外的 tasklet 和 软中断。不需要禁用下半部。123456789//禁止中断同时获取锁的 接口，会保存中断的状态，没有激活的中断不会被激活spin_lock_irqsave(&amp;mr_lock, flags);/* critical region ... */ spin_unlock_irqrestore(&amp;mr_lock, flags);//明确中断是激活的状态下，用以下代码，解锁后直接激活。spin_lock_irq(&amp;mr_lock); /* critical section ... */ spin_unlock_irq(&amp;mr_lock); 内核配置选项 CONFIG_DEBUG_SPINLOCK 和 CONFIG_DEBUG_LOCK_ALLOC 帮助调试锁操作 自旋锁的函数 函数 描述 spin_lock() Acquires given lock spin_lock_irq() Disables local interrupts and acquires given lock spin_lock_irqsave() Saves current state of local interrupts, disables local inter- rupts, and acquires given lock spin_unlock() Releases given lock spin_unlock_irq() Releases given lock and enables local interrupts spin_unlock_irqrestore() Releases given lock and restores local interrupts to given pre- vious state spin_lock_init() Dynamically initializes given spinlock_t 获得一个spinlock_t类型的指针 spin_trylock() Tries to acquire given lock; if unavailable, returns nonzero spin_is_locked() Returns nonzero if the given lock is currently acquired, other- wise it returns zero 读写自旋锁一个链表读操作是可以并发的，写操作只能一个进程执行，并且在写的时候不允许读，这种就可以用读写自旋锁。但是有可能多个读者一直占用锁，造成写者等待过久。 123456789101112131415//初始化DEFINE_RWLOCK(mr_rwlock);//Then, in the reader code path:read_lock(&amp;mr_rwlock);/* critical section (read only) ... */ read_unlock(&amp;mr_rwlock);//Finally, in the writer code path:write_lock(&amp;mr_rwlock);/* critical section (read and write) ... */ write_unlock(&amp;mr_lock);//下面代码会带来死锁，因为写锁会一直等待读锁释放。read_lock(&amp;mr_rwlock); write_lock(&amp;mr_rwlock); 如果你在中断处理程序使用 read_lock()而不是read_lock_irqsave()那需要额外禁止写操作中断write_lock_irqsave()，否则会造成死锁。 信号量Linux 中的信号量是一种睡眠锁,当任务获取一个被占用的信号量时，回进入等待队列进行睡眠，CPU 去执行其他任务。 在占有信号量的同时不能占有自旋锁。等待信号量的时候回去睡眠。 信号量不会禁止内核抢占。 计数信号量和二值信号量 二值信号量：同时最多一个任务持有信号量锁。常用，也叫互斥信号量。计数信号量：允许同一时刻多个任务持有信号量，在声明的时候指定数量，用的不多。 信号量的获取与释放两个原子操作 P()/down() 和 V()/up() ，down()操作后，计数减1，大于等于0，获取锁，小于0进入队列并睡眠。临界区操作完成后，up()释放信号量计数加1. 读写信号量 几乎和读写自旋锁一样，提供了一个down_read_trylock()转换读写锁。 信号量的实现123456789101112131415161718192021222324252627//信号量的实现与体系结构相关 代码在&lt;asm/semaphore.h&gt;创建和初始化：// count 是计数struct semaphore name; sema_init(&amp;name, count);//创建互斥信号量static DECLARE_MUTEX(name);//动态创建sema_init(sem, count);init_MUTEX(sem);信号量的使用：/* define and declare a semaphore, named mr_sem, with a count of one */static DECLARE_MUTEX(mr_sem);/* attempt to acquire the semaphore ... */ if (down_interruptible(&amp;mr_sem)) &#123;/* down_interruptible(&amp;mr_sem) 获取信号量，如果不可用，是进程进入睡眠TASK_INTERRUPTIBLEsignal received, semaphore not acquired ... */&#125;/* critical region ... *//* release the given semaphore */ up(&amp;mr_sem); 互斥体(mutex)可以视为特别的信号量，指的是任何可以睡眠的强制互斥锁（计数只能是1），比如计数为1的信号量。mutex 对应数据结构是 mutex，操作接口简单，实现高效，使用限制强。 函数 描述 DEFINE_MUTEX(name); 静态定义 mutex_init(&amp;mutex); 动态定义 mutex_lock(struct mutex *) Locks the given mutex; sleeps if the lock is unavailable mutex_unlock(struct mutex *) Unlocks the given mutex mutex_trylock(struct mutex *) Tries to acquire the given mutex; returns one if suc- cessful and the lock is acquired and zero otherwise mutex_is_locked (struct mutex *) Returns one if the lock is locked and zero otherwise mutex不能在中断和下半部使用 持有mutex的进程不能退出 首选mutex，如果不能满足其约束条件，在使用信号量。 锁的选择 需求 选择的加锁方式 Low overhead locking Spin lock Short lock hold time Spin lock Long lock hold time Mutex Need to lock from interrupt context Spin lock Need to sleep while holding lock Mutex 其他锁完成变量(Completion Variables)Completion Variables 一个任务在等待另一个任务完成，这个任务完成工作后唤醒等待的任务。vfork()就是使用这个来唤醒父进程。 顺序锁（seq）一种新型锁，依靠序列计数器，写操作会+1 ，读数据前后会读取这个数，值相同代表没有写入。 jiffies_64 使用的是 seq 锁12345678910111213u64 get_jiffies_64(void) &#123; unsigned long seq; u64 ret; do &#123; seq = read_seqbegin(&amp;xtime_lock); ret = jiffies_64; &#125; while (read_seqretry(&amp;xtime_lock, seq)); return ret;&#125;// 更新定时器的写锁write_seqlock(&amp;xtime_lock); jiffies_64 += 1; write_sequnlock(&amp;xtime_lock); 禁止抢占单CPU 可能不需要自旋锁，这时候会遇到伪并发，抢占进程操作同一个数据的情况。123preempt_disable(); //禁止内核抢占，抢占计数+1/* preemption is disabled ... */ preempt_enable(); 顺序和屏障程序代码编译后，在 cpu 中执行的顺序可能会被 CPU 重新排序，可以用屏障的方法来固定顺序。函数|描述–|–rmb() |Prevents loads from being reordered across the barrierread_barrier_depends() |Prevents data-dependent loads from being re- ordered across the barrierwmb() |Prevents stores from being reordered across the barriermb() |Prevents load or stores from being reordered across the barrierbarrier() |Prevents the compiler from optimizing stores or loads across the barrier]]></content>
      <tags>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内核的同步以及锁机制]]></title>
    <url>%2F2018%2F08%2F12%2F5-%E5%86%85%E6%A0%B8%E7%9A%84%E5%90%8C%E6%AD%A5%E4%BB%A5%E5%8F%8A%E9%94%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[1.前言为什么要考虑内核同步 在单一CPU 的情况下，中断或者内核代码明确调度时，多个执行线程并发访问共享数据。目前多处理器以及抢占式内核的存在，更需要注意保护共享资源。 造成并发的原因 Interrupts— An interrupt can occur asynchronously at almost any time, interrupting the currently executing code. Softirqs and tasklets— The kernel can raise or schedule a softirq or tasklet atalmost any time, interrupting the currently executing code. Kernel preemption— Because the kernel is preemptive, one task in the kernelcan preempt another. Sleeping and synchronization with user-space— A task in the kernel cansleep and thus invoke the scheduler, resulting in the running of a new process. Symmetrical multiprocessing— Two or more processors can execute kernelcode at exactly the same time. 临界区临界区( Critical Regions ) 指的是访问内存中共享数据的 代码段，编程者需要保证这一部分代码段执行期间不被打断。如果两个线程在同一个临界区执行，就会有Bug。避免这种情况发生称之为 同步(synchronization). 例子比如银行取款的代码，同一个账号同时在用两种方式取款，需要调用同一个取款函数，这时候必须考虑同步。有两种方法来解决这个问题，一个是原子性，一个是加锁。 将取款的整个函数原子化,使得每一个事务是原子性并且不可打断的。CPU 和内核提供了原子操作的接口（算术运算或比较大小）。 有时候共享数据是一个复杂的数据结构，例如队列等不定长度的数据类型,这种复杂的情况没有办法原子化,就需要用到加锁 2.加锁 锁的机制就像一个房间的门锁一样，房间内只能有一个线程存在。后来的线程需要在门外排队。 linux 自身实现了几种不同的锁，主要体现在锁在被占用的情况下的表现。 加锁的过程是采用原子操作实现的，和体系结构相关。一般 0 意味着开锁。 伪并发与真并发 都存在竞争，都需要保护。 伪并发是指单处理器系统中，一个程序在运行中被调度到另一个程序，两个程序执行在一个临界区。 真并发是指在多处理器系统中，两个程序同时执行，执行在一个临界区。 加锁的方法并不难，难的是找到哪些数据和临界区需要加锁，在编写代码的时候就要考虑到 Is the data global? Can a thread of execution other than the current one access it? Is the data shared between process context and interrupt context? Is it shared between two different interrupt handlers? If a process is preempted while accessing this data, can the newly scheduled process access the same data? Can the current process sleep (block) on anything? If it does, in what state does that leave any shared data? What prevents the data from being freed out from under me? What happens if this function is called again on another processor? Given the proceeding points, how am I going to ensure that my code is safe fromconcurrency? 不需要加锁的数据 局部变量，只被特定进程访问的数据 需要加锁的数据 大多数内核的数据结构，有其他线程可以访问的数据 内核在编译时是可以配置的，可以不设置SMP 以及 抢占的模块，减少开销。 3.死锁死锁的产生条件：一个或多个执行线程，和一个或多个共享数据。 ==彼此需要的资源被彼此锁住了== 。 自死锁，等待自己已经拿到的锁 避免死锁的规则： 按顺序加锁，多个线程按照同样的顺序获得多个锁， A - B -C 这样 第二个进程就不会先获得C 造成死锁。 防止发生饥饿 不重复请求同一个锁 设计应简单 内核提供了调试工具在运行时检测死锁 4.扩展性 并不是多CPU 就是成倍的增加性能，因为共享数据的锁，需要排队等待锁机制。 锁的加锁 ==粒度==，是对一个大块数据加锁还是对大块数据的一个元素加锁。 可以对(一整个链表/链表的一个节点/节点的一个元素)进行加锁。 锁的增用严重的话，就需要使加锁的粒度更精细，但是粒度过于精细也会使得系统开销增大 调度队列 O(1) 到 CFS 就提高了精细度]]></content>
      <tags>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内核中链表(Linked List)的实现]]></title>
    <url>%2F2018%2F08%2F11%2F4-%E5%86%85%E6%A0%B8%E4%B8%AD%E9%93%BE%E8%A1%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[前言内核中链表是比较简单的数据结构，通过两个指针元素实现双向链表。链表相比其他数据结构的优点是不占用连续的内存，可以动态的插入和删除节点。 比较简单的链表链表中前后指针元素和数据元素在同一个结构体中。通过指针可以直接找到数据。 单向链表1234struct list_element &#123; void *data; struct list_element *next;&#125; 双向链表12345struct list_element &#123; void *data; struct list_element *next; struct list_element *prev;&#125; linux 内核中双向链表的实现linux 内核中的链表数据结构中存放的是链表节点，而不是数据节点，通过链表指针来查找数据元素。 存放数据的结构体123456struct fox &#123; unsigned long tail_length; /* length in centimeters of tail */ unsigned long weight; /* weight in kilograms */ bool is_fantastic; /* is this fox fantastic? */ struct list_head list; /* list of all fox structures */&#125;; 存放链表指针的结构体1234struct list_head &#123; struct list_head *next struct list_head *prev;&#125;; container_of()宏链表数据结构中只存放 list_head 类型的数据结构，那么怎么通过 list_head 元素得到所在的数据呢，通过container_of()宏,使用 list_head 的地址已经数据元素的偏移量来获取数据内容 12345#define container_of(ptr, type, member) (&#123; \const typeof( ((type *)0)-&gt;member ) *__mptr = (ptr); \(type *)( (char *)__mptr - offsetof(type,member) );&#125;)强制转换 ptr 格式，ptr 是 list_head 地址，type fox 结构体的类型,类型不同偏移量可能不同，Member list_head 的名字 上述内核代码在 &lt;linux/list.h&gt; 中声明 内核中链表的使用下面是内核中一些已经定义好的增删便利的函数。123456789101112131415161718192021static LIST_HEAD(fox_list);list_add(struct list_head *new, struct list_head *head)list_add(&amp;f-&gt;list, &amp;fox_list);list_add_tail(struct list_head *new, struct list_head *head)list_del(struct list_head *entry)static inline void __list_del(struct list_head *prev, struct list_head *next) &#123; next-&gt;prev = prev; prev-&gt;next = next; &#125; list_move(struct list_head *list, struct list_head *head)struct list_head *p; struct fox *f;list_for_each(p, &amp;fox_list) &#123; /* f points to the structure in which the list is embedded */ f = list_entry(p, struct fox, list);&#125; 自己手写的链表实验12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;stddef.h&gt;#include &lt;stdio.h&gt;struct list_head &#123; struct list_head *prev; struct list_head *next;&#125;;struct fox &#123; unsigned long l; /* length in centimeters of tail */ int w; /* weight in kilograms */ struct list_head list; char asd;&#125;;struct dog &#123; int a ; int b ; struct list_head dogList;&#125;;static void add_list(struct list_head *new,struct list_head *head)&#123; new-&gt;next = head-&gt;next; head-&gt;next-&gt;prev = new; head-&gt;next = new; new-&gt;prev = head;&#125;#define container_of(ptr,type,member) (&#123; \ const typeof (((type *)0)-&gt;member) *_mptr = (ptr); \ (type *)((char *)_mptr - offsetof(type,member)) ; \&#125;)/* static inline struct list_head LIST_HEAD_INIT(struct list_head list)&#123; list.next = &amp;list; list.prev = &amp;list; return list;&#125;*/#define LIST_HEAD_INIT(name) &#123; &amp;(name), &amp;(name) &#125;int main() &#123; struct fox fox1 = &#123; .l = 40, .w = 20, .list = LIST_HEAD_INIT(fox1.list), &#125;; struct dog wang = &#123;1,2,LIST_HEAD_INIT(wang.dogList)&#125;; add_list(&amp;wang.dogList,&amp;fox1.list); printf(&quot;%lx\n&quot;,(long)&amp;fox1); printf(&quot;%lx\n&quot;,(long)&amp;fox1.list); printf(&quot;%ld\n&quot;,(long)sizeof(struct fox)); printf(&quot;%lx\n&quot;,(long)container_of(&amp;fox1.list,struct fox,list)); printf(&quot;%lx\n&quot;,(long)container_of(fox1.list.next,struct dog,dogList)); printf(&quot;%d\n&quot;,(container_of(fox1.list.next,struct dog,dogList))-&gt;b); return 0;&#125;]]></content>
      <tags>
        <tag>kernel</tag>
        <tag>list</tag>
        <tag>c languages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo + Github 的个人博客搭建]]></title>
    <url>%2F2018%2F08%2F11%2F3-Hexo-Github%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[前言本篇介绍如何使用 hexo 和 github page 来搭建个人博客， hexo 是一个博客框架,支持 markdown，有丰富的插件和主题。github page 是 github 的一个项目，给开发者提供一个免费的没有空间限制的私人页面。 配置 github1.创建 github 账号 https://github.com/ 2.创建一个新项目 new reposity项目必须要遵守格式：账户名.github.io， 不然接下来会有很多麻烦。并且需要勾选Initialize this repository with a README 3. 按照图片输入信息在建好的项目右侧有个settings按钮，点击它，向下拉到GitHub Pages。开启后访问一下你的链接，应该可以看到默认的GitHub Pages效果 打开链接 账户名.github.io 可以看到默认的github page 页面 配置 Hexo安装 Hexo 安装 nodejs 安装 nodejs 后才可以安装 hexo http://nodejs.cn/ 安装 git 用来将 clone github 上的 hexo 主题 https://git-scm.com/downloads 使用 npm 安装 Hexo 123# npm install -g hexo-cli- 一键安装 使用 Hexo 初始化 Hexo 1234hexo i blog //init的缩写 blog是项目名，初始化项目cd blog //切换到站点根目录hexo g //generetor的缩写 渲染hexo s //server的缩写,开启 hexo 服务 打开浏览器输入localhost:4000查看默认页面 看到页面就说明成功了，这个就是hexo默认的博客主题。现在你已经可以在这个主题下写博客了。当然，我是不喜欢这样的，幸好，github上有大量的主题可供选择，这里我选择使用nexT主题。 切换主题 在站点根目录输入 git clone https://github.com/theme-next/hexo-theme-next themes/next 打开根目录下的配置文件 _config.yml 修改主题12345678910$ vim ../hexo/_config.yml theme: next$ vim /themes/next/_congig.yml # Schemes //next 的三种主题#scheme: Muse # 右边目录，首页居中scheme: Mist # 右边弹目录,首页左上#scheme: Pisces # 桌面目录，文章空间小#scheme: Gemini # 同上，首页博客分割# Canvas-nest # 动态背景canvas_nest: false 清楚缓存，重新渲染 12345$ hexo clean //清除缓存$ hexo g //重新生成代码$ hexo s //部署到本地//然后打开浏览器访问 localhost:4000 查看效果 将本地的 hexo 代码上传到 Github Page 上 修改hexo站点的配置文件 123456$ vim /hexo/_config.ymldeploy: type: git repository: https://github.com/Tomoku-dm/Tomoku-dm.github.io branch: master message: update 部署 12345$ npm install hexo-deployer-git --save//先装个插件压压惊$ hexo d // 部署的命令//等一会就好了,这回可以直接访问 Github Page 的网址了 添加博客文章文章目录是 /blogpath/source/_posts/xxx.md添加文章后重新渲染及部署12$ hexo g //生成静态页面$ hexo d //发布 关于 next 主题配置可以参考下面这些链接https://www.jianshu.com/p/9f0e90cc32c2 hexo 的 _config 可以修改： 语言、作者、title、座右铭]]></content>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Snapper 快照管理工具]]></title>
    <url>%2F2018%2F06%2F17%2F2-snapper%2F</url>
    <content type="text"><![CDATA[简介Snapper是一个用来创建和维护快照的命令行工具，提供了基本的快照工具：创建、删除快照；对比快照之间的变化，以及撤销快照之间的操作。 关于快照 快照是对卷在某一点上进行拷贝，提供了一种恢复文件系统到之前状态的一种方法。关于快照的实现，有两种的方法 写时复制Copy On Write (COW) 即在数据第一次写入到某个存储位置时，首先将原有的内容读取出来，写到另一位置处（为快照保留的存储空间，此文中我们称为快照空间），然后再将数据写入到存储设备中。而下次针对这一位置的写操作将不再执行写时复制操作。从COW 的执行过程我们可以知道，这种实现方式在第一次写入某个存储位置时需要完成一个读操作（读原位置的数据），两个写操作（写原位置与写快照空间），如果写入频繁，那么这种方式将非常消耗IO时间。 重定向写快照 Redirect-on-write (ROW) “ROW重定向写”与“COW复制写”是相对的概念，它可以避免两次写操作引起的性能损失。ROW把对数据卷的写请求重定向给了快照预留的存储空间，而写操作的重定向设计则把需要两次写才能完成的操作减少为一次写。我们知道COW的两次写包括：1、将旧数据写入快照卷;2、在数据卷写入新数据。而ROW只有写入新数据一步。使用ROW快照，数据卷存放的是上一个快照时间点的旧数据，新数据最终存放在预留的快照空间。 sanpper 优点 可以使用Snapper来安装/升级软件，在安装/升级前后做快照，如果安装/升级失败，就可以快速的恢复系统到正常状态 Snapper可以帮助快速定位哪些配置文件做了改动，帮助定位错误，并快速撤销配置文件的修改。 自动做快照 sanpper 缺点 只支持Btrfs 和 thinly-provisioned LVM 文件系统。 在创建快照时并没有能确保数据一致性的机制。 不能计算快照实际大小（未知） 配置文件Snapper 需要为每一个卷创建一个配置文件，配置文件定义了快照的创建和维护规则。Snapper 的每一个操作都是根据卷对应的配置文件进行的。 创建配置文件 snapper -c lvm_config create-config -f “lvm(ext4)” /lvm_mount 配置文件模板 /etc/snapper/config-templates/default源文件位置 Snapper 的快照数据存储在当前子卷根目录的 .snapshots 隐藏文件夹中 /mnt/test/.snapshots 列出所有的配置文件1234[root@45-rh72-ser test]# snapper list-configs 配置 | 子卷 ---------+----------test_con | /mnt/test 配置文件参数 TIMELINE_CREATE :如果设置为yes，便会每小时创建一个快照。这是目前唯一一种可以自动创建快照的方式，因此强烈建议将其设置为 yes。 ALLOW_USERS 和（或）ALLOW_GROUPS：分别为用户和（或）组授予权限。多个条目需要使用空格 分隔。例如，要为用户 thin_user 和 thin_group 授予权限，可运行： snapper -c web_data set-config “ALLOW_USERS=thin_user” “ALLOW_GROUPS=thin_group” snapper 的三种快照迭代方式 使用快照快照种类 Pre Snapshot：修改前的文件系统快照。每一张前快照都有一个对应的post快照。 Post Snapshot：修改后的文件系统快照。每一张后快照都有一个对应的pre快照。 Single Snapshot：独立的快照。目的之一就是为了自动创建每小时快照。此为创建快照时的默认类型。 创建快照12345678910111213# snapper -c config_name create -t pre -p (打印编号)# snapper -c config_name create -t post -p# snapper -c btrfs_config create --command &quot;yum install net-tools&quot; 实现三步操作（1.pre 2.yum 3.post） 在测试中很实用# snapper -c lvm_config create -t single # snapper -c test_con list 查看所有的快照类型 | # | 前期 # | 日期 | 用户 | 清空 | 描述 | 用户数据-------+---+--------+------------------------------------+------+----------+----------+---------single | 0 | | | root | | current | pre | 1 | | 2017年11月16日 星期四 15时57分40秒 | root | | | single | 2 | | 2017年11月16日 星期四 16时01分01秒 | root | timeline | timeline | post | 3 | 1 | 2017年11月16日 星期四 16时09分47秒 | root | | 比对快照的差异 第一列 “+”号代表新增文件，“-”代表删除文件，“c”代表修改了文件，. 什么都没变，”t” 文件属性变了，例如链接之类的。与diff语法相同。 第二列 权限的改变 .没改 p改了 第三列 用户 第四列 组 第五列 extended attributes 第六列 acl 1234567891011121314[root@45-rh72-ser test]# snapper -c lvm_config status 3..4 看每一个快照之间的简单变化+..... /lvm_mount/hello_file [root@45-rh72-ser test]# snapper -c test_con diff 10..11 /mnt/test/wwww --- /mnt/test/.snapshots/10/snapshot/wwww 1970-01-01 08:00:00.000000000 +0800+++ /mnt/test/.snapshots/11/snapshot/wwww 2017-11-16 16:57:04.407000000 +0800@@ -0,0 +1 @@+asdasd[root@45-rh72-ser configs]# snapper -c test_con xadiff 30..31--- /mnt/test/.snapshots/30/snapshot/wwww+++ /mnt/test/.snapshots/31/snapshot/wwww +:user.abc 恢复快照与删除快照123[root@45-rh72-ser test]# snapper -c config_name undochange 1..2 取消1到2的更改# snapper -c btrfs_config delete 1 2 删除快照，应该先删除旧快照 过滤规则一些文件主要用来保存系统信息，例如/etc/mtab，这类文件不希望被快照操作影响到，Snapper允许通过/etc/snapper/filters/*.txt 指定过滤项，并在快照操作中忽略指定文件或文件夹的变化。 例如我们的btrfs中我们不希望快照跟踪/var、/tmp等，可以添加到filters，这样在以后创建的快照中就看到不到关于/var、/tmp的快照跟踪了。]]></content>
      <tags>
        <tag>linux</tag>
        <tag>storage</tag>
        <tag>snapshoot</tag>
      </tags>
  </entry>
</search>
